[{"body":"Getting Started with ViaductTo get you started with Viaduct, we have a created a number of small demonstration applications to illustrate what is a Viaduct application and how you write and build one. You can find these at github.com/viaduct-graphql. In particular, in order of complexity, we have a CLI starter, a Spring starter, and a more full-featured StarWars application. This document walks you through the CLI starter in some detail, and provides suggestions for how to explore the other two.\nRequirementsJava 21 must be on the path or available via JAVA_HOME.\nWe assume a basic familiarity with GraphQL. The GraphQL Foundation has excellent learning materials on this topic.\nRunning the Simple ApplicationStart by making a local clone of the CLI starter:\ngit clone https://github.com/viaduct-graphql/cli-starter.git Next cd into that clone and test that your environment is ready by typing:\n./gradle test After building and testing the CLI demo, Gradle should report that the build was successful.\nAlthough Viaduct is typically hosted in a Web server, to keep things simple the CLI demo simply calls it directly from the application’s main directory. You can do this through Gradle:\n./gradlew -q run --args=\"'{ greeting }'\" Here is the full schema for this simple application:\ntype Query { greeting: String @resolver author: String @resolver } Through the command line you issue any query against this schema.\nTouring the ApplicationThe main elements of this application’s source-code directory are the following:\nbuild.gradle.kts src/ main/viaduct/schema/schema.graphqls main/kotlin/com/example/viadapp/ViaductApplication.kt main/kotlin/com/example/viadapp/resolvers/HelloWorldResolvers.kt ... ... You can see that a Viaduct application is a Gradle project. The file:\nschema.graphqls contains the GraphQL schema for the application. All files matching **/*.graphqls in that directory collectively define the schema of the application\nViaductApplication.kt contains the main function for this command-line tool. This function creates an instance of a Viaduct engine and sends the query it gets as its command-line argument to that engine.\nHelloWorldResolvers.kt contain the “application logic” for our schema, the code that says how to resolver the fields of the schema.\nAt the top of build.gradle.kts you’ll see:\nplugins { alias(libs.plugins.kotlinJvm) alias(libs.plugins.viaduct.application) alias(libs.plugins.viaduct.module) application } You can see the two Viaduct plugins appearing here. Viaduct applications are structured as multi-project Gradle builds. The root project must contain the application plugin shown above: this plugin coordinates certain build processes across the engine application. In addition, one or more projects also apply the module plugin, which indicates that that project contains application code (in our case, the code found in HelloWorldResolvers.kt). As this example shows, a Viaduct application can be as simple as a single project build, in which case both plugins are applied to taht one project.\nExtending the ApplicationExtending the SchemaLet’s explore our sample application more deeply by extending its functionality. Viaduct is a “schema first” GraphQL environment, meaning you write your schema first, and then generate classes to write your code against. So in that spirit, let’s start by extending the schema in schema.graphqls (in the location noted above). You should see the following in that file:\nextend type Query { greeting: String @resolver author: String @resolver } Viaduct itself has built-in definitions for the root GraphQL types Query and Mutation (Viaduct doesn’t yet support subscriptions). Since Query is built-in, application code should extend it as illustrated above. You’ll also see in this schema fragment that both fields have @resolver applied to them, meaning that a developer-provided function is needed to compute their respective value. (All fields of Query must have @resolver applied to them.)\nLet’s extend this schema to add a new field, attributedGreeting, which will attribute the greeting to its author:\nextend type Query @scope(to: [\"publicScope\"]) { greeting: String @resolver author: String @resolver attributedGreeting: AttributedGreeting @resolver } type AttributedGreeting { greeting: String } There’s no practical reason to have the AttributedGreeting type here: attributedGreeting could’ve just been a String. We’re using a GraphQL object-type here in order to demonstrate some features of our API.\nExtending the codeAfter you make a schema change, in your application root directory (the one that applies the application plugin) you need to run ./gradlew generateViaductGRTs generateViaductResolverBases. This will regenerate the code needed to build your application. (We’re working to streamline this.)\nHaving done that, you need to write a resolver for our new field. Actually, you could add it to HelloWorldResolvers.kt: resolvers for this application can be placed to any file as long it’s in the com.example.viadapp.resolvers package. To support copy-and-paste, create a file named AttributedGreetingResolver.kt (or whatever) in the same subdirectory as HelloWorldResolvers.kt and copy the following code into it:\npackage com.example.viadapp.resolvers import viaduct.api.Resolver import com.example.viadapp.helloworld.resolverbases.QueryResolvers import viaduct.api.grts.AttributedGreeting // The class generated for our AttributedGreeting type // New code: @Resolver(\"\"\" greeting author \"\"\") class AttributedGreetingResolver : QueryResolvers.AttributedGreeting() { override suspend fun resolve(ctx: Context): AttributedGreeting { val greeting = ctx.objectValue.getGreeting() val author = ctx.objectValue.getAuthor() return AttributedGreeting.Builder(ctx) .greeting(\"$author says: \\\"$greeting\\\"\") .build() } } The basic idea is that the resolver for attributedGreeting will combine author and greeting into a string that attributes the greeting to the author. The resolver has access to these two fields because its @Resolver annotation indicates that it needs those fields: if the @Resolver annotation didn’t mention the author field, for example, then the attempt to read objectValue.author() would fail at runtime.\nLet’s examine some of the details of Viaduct that are illustrated by this file:\nFor every GraphQL type, Viaduct generates a Kotlin interface or class to represent it in code. We call these GraphQL Representational Types, or GRTs for short. These GRTs are all placed in the viaduct.api.grts package.\nViaduct generates also generate a resolver base class for writing resolvers. For each field Type.field with an @resolver directive in the schema, we generate a base class Type.Field. As illustrated by our example, to write a resolver for that field, you subclass this base class and override the resolve function.\nYou can save this file and the run:\n./gradlew -q run --args=\"'{ attributedGreeting }'\" and you should see the appropriate response.\nWhat’s NextStarWars Deep Dive. The StarWars application comes with a deep dive document describing Viaduct features in some detail.\nDocumentation. Explore our documentation site.\nBuilding your own application. Pick the structure that you like best - single project, two project (root plus on module), or multi-module. Make a copy of the respective demo app (CLI, Spring, or StarWars) and make a copy.\n","categories":"","description":"Setting up and modifying a simple Viaduct application","excerpt":"Setting up and modifying a simple Viaduct application","ref":"/viaduct/docs/getting_started/","tags":"","title":"Getting Started"},{"body":"SchemaNodes are types that are resolvable by ID and implement the Node interface. Every object type that implements the Node interface has a corresponding node resolver.\ninterface Node { id: ID! } type User implements Node { id: ID! firstName: String lastName: String displayName: String @resolver } Generated base classViaduct generates an abstract base class for all object types that implement Node. For the User example above, Viaduct generates the following code:\nobject NodeResolvers { abstract class User { open suspend fun resolve(ctx: Context): viaduct.api.grts.User = throw NotImplementedError() open suspend fun batchResolve(contexts: List\u003cContext\u003e): List\u003cFieldValue\u003cviaduct.api.grts.User\u003e\u003e = throw NotImplementedError() class Context: NodeExecutionContext\u003cviaduct.api.grts.User\u003e } // If there were more nodes, their base classes would be generated here } The nested Context class is described in more detail below.\nImplementationImplement a node resolver by subclassing the generated base class and overriding exactly one of either resolve or batchResolve.\nHere’s an example of a non-batching resolver for User that calls a user service to get data for a single user:\nclass UserNodeResolver @Inject constructor( val userService: UserServiceClient ): NodeResolvers.User() { override suspend fun resolve(ctx: Context): User { // Fetches data for a single User ID val data = userService.fetch(ctx.id.internalId) return User.builder(ctx) .firstName(data.firstName) .lastName(data.lastName) .build() } } Points illustrated by this example:\nDependency injection can be used to provide access to values beyond what’s in the execution context. You should not provide values for fields outside the resolver’s responsibility set. In the example above, we do not set displayName when building the User GRT. Alternatively, if the user service provides a batch endpoint, you should implement a batch node resolver. Node resolvers typically implement batchResolve to avoid the N+1 problem. Learn more about batch resolution here.\nContextBoth resolve and batchResolve take Context objects as input. This class is an instance of NodeExecutionContext :\ninterface NodeExecutionContext\u003cT: NodeObject\u003e: ResolverExecutionContext { val id: GlobalID\u003cT\u003e fun selections(): SelectionSet\u003cT\u003e } For the example User type, the T type would be the User GRT.\nNodeExecutionContext includes the ID of the node to be resolved, and the selection set for the node being requested by the query. Most node resolvers are not “selective,” i.e., they ignore this selection set and thus don’t call this function. In this case, as discussed above, it’s important that the node resolver returns its entire responsibility set.\nAdvanced users: If the selections function is not called by an invocation of a resolver, then the engine will assume that invocation will return the full responsibility set of the resolver and may take actions based on that assumption. If a resolver is going to be selective, then it must call this function to get its selection set rather than obtain it through some other means.\nSince NodeExecutionContext implements ResolverExecutionContext, it also includes the utilities provided there, which allow you to:\nExecute subqueries Construct node references Construct GlobalIDs Responsibility setThe node resolver is responsible for resolving all fields, including nested fields, without its own resolver. These are typically core fields that are stored together and can be efficiently retrieved together.\nIn the example above, the node resolver for User is responsible for returning the firstName and lastName fields, but not the displayName field, which has its own resolver. Note that node resolvers are not responsible for the id field, since the ID is an input to the node resolver.\nNode resolvers are also responsible for determining whether the node exists. If a node resolver returns an error value, the entire node in the GraphQL response will be null, not just the fields in the node resolver’s responsibility set.\n","categories":"","description":"Writing resolvers for nodes in Viaduct","excerpt":"Writing resolvers for nodes in Viaduct","ref":"/viaduct/docs/developers/resolvers/node_resolvers/","tags":"","title":"Node Resolvers"},{"body":"Viaduct ArchitectureThis document provides a high-level description of Viaduct’s software architecture and how that relates to the organization of its source code. Viaduct consists of two main pieces, the runtime system and the build-time system. We look at each in turn.\nRuntime ArchitectureSoftware LayersThe following diagram illustrates the layers that make up the Viaduct architecture and the personas responsible for each layer:\nViaduct architecture layers and developer personas.\nOverall a Viaduct application consists of two layers, the Viaduct Framework, i.e., the open-source software found in github.com/airbnb/viaduct, plus the application software that sits on top of that. In addition, it’s organized into two “stacks,” the service stack and the application stack.\nThe Viaduct Framework in turn consists of two internal layers: the engine and the tenant developer API. The engine implements the GraphQL execution algorithms. Internally this layer is written in a dynamically-typed manner: think of GraphQL objects represented as maps from field names to Any? values (it’s more complicated than that, but directionally that’s the way to think about it). The tenant developer API provides an ergonomic layer for application developers sitting on top of this lower-level. Among other things, the tenant developer API presents statically-typed wrappers around the lower-level, dynamically-type engine objects, providing type safety for application code.\nViaduct was designed to support multiple different tenant developer APIs running at the same time. In fact, inside of Airbnb, we run two tenant developer APIs, one that implements our “Classic” tenant developer API supporting the 1.5M lines of existing code running in Viaduct today, as well as the new “Modern” tenant developer API which ships with the open-source code. In the future, we hope to implement a native Java API for writing Java-based application code, and even a JavaScript API. In our multi-tenant-API, these APIs would interoperate, e.g., a Viaduct installation could support application code written in both Kotlin and JavaScript. Running on top of the Viaduct Framework is an installation’s application code.\nViaduct is also organized into two stacks:\nThe Service Stack contains the “Main” function that starts up a Viaduct application. Typically, this function creates a Web server that routes HTTP requests to the Viaduct engine. However, in some contexts the Main function might integrate the Viaduct engine into a test harness, or even a command-line tool. This Main function sits on top of a thin layer of software inside of Viaduct called the “service domain.” (We’ll say more about “domains” later.) The service domain consists mainly of factories and other abstractions that allow one to configure a Viaduct engine.\nThe Application Stack executes GraphQL operations, calling into application code as appropriate.\nAPIs and SPIsThe Viaduct architecture carefully distinguishes Service Provider Interfaces from Application Programming Interfaces. The arrows on the right side of the diagram indicate the difference between the two. SPIs call “up” through the software layers, enabling the Viaduct framework to call “into” application level code. APIs call “down” through the software layers, enabling Viaduct application code to invoke functionality provided by the framework. We’ll illustrate the difference shortly in the Sequence Diagram section. (Perhaps confusingly, we often use the term “API” imprecisely to refer collectively to both what we’re defining as the API and SPI here. TODO: Need some kind of qualifier for API we can use when we need to be more precise.)\nDeveloper PersonasIn our software architecture we identify four developer personas. Two of these – engine and tenant-API developers – work on their respective sublayers of the framework. (We consider the service domain to be an extension of the engine, and thus in the purview of engine developers.)\nThe other two personas work on applications running on top of the framework. Application developers are those who write the actual application, crafting the central schema and the business logic that make up a particular application. Service Engineers are those who integrate Viaduct into an organization’s IT stack. These include integrations into the organization’s preferred Web-serving framework, observability infrastructure, access-control platforms, and dependency-injection framework. These integrations are performed mostly by utilizing the SPIs mentioned earlier. Where multiple tenant-APIs are available, Service Engineers configure which ones are actually provisioned at runtime. Service Engineers are also responsible for organizing an application’s source code, setting up the build system and integrating it into the organization’s CI/CD infrastructure.\nRequest Sequence DiagramThe following sequence diagram follows the lifecycle of an operation, highlighting the respective roles of the API and SPI:\nA sequence diagram of the lifecycle of an operation.\nThe text in each of the “participant” boxes consists of two lines: the first line names the “API” abstractions, where the second line names the “SPI” abstractions (in every participant except for Main/SPI, the names given are the names of actual types in the Viaduct source code). In this diagram, solid-line arrows represent API calls as defined above, and dotted-lines represent SPI calls.\nThe Viaduct interface lives in the service domain and is the entry from the application’s “Main” function into the engine. As mentioned earlier, this is really a thin wrapper around an Engine object. So through Viaduct execution of an operation enters the Engine, which implements the GraphQL execution algorithm, invoking tenant module resolvers where appropriate. The sequence diagram illustrates how these invocations work. The Engine calls an SPI it defines called ResolverExecutor (there are two of these: NodeResolverExecutor and FieldResolverExecutor). The tenant-API implementation is responsible for providing instances of these resolver executors that perform the “wrapping” mentioned above – wrapping the dynamically-typed Engine abstractions with compile-time typed tenant developer API abstractions – and then calls an SPI that it (the tenant-API implementation) defines called ResolverBase.\nTo invoke the application-layer resolver code, the tenant-API implementation first needs to create an instance of the ResolverBase subclass containing the resolver function. This occurs by using an instance of TenantCodeInjector (an SPI) provisioned by Service Engineers when the configure Viaduct.\nOnce this chain of SPI enters into tenant module code, that tenant module code in turn uses the tenant developer API’s API abstractions – such as ExecutionContext – to leverage functionality provided to by the framework. In this particular example, the resolver is creating a “node reference” by calling ExecutionContext.nodeFor. Under the covers, the tenant-API’s implementation uses an EngineExecutionContext object – EngineExecutionContext.createNodeEngineObjectData in particular – to create this node reference. In our hypothetical example, this node reference is what is then returned by the resolver function, and in turn the ResolverExecutor, back to the engine.\nSource Code StructureAs implied above, the source code for the Viaduct Framework is divided into three Gradle projects: engine, service, and tenant. Each of these projects is organized into three Gradle subprojects: api, runtime, and wiring. The api subproject (which defines, e.g., the viaduct.engine.api package hierarchy) defines the API for the project (the engine API in this example). The SPI for the project is also in the api subproject (viaduct.engine.api.spi in the case of the engine). The api packages typically define Kotlin interfaces rather than classes. The runtime subproject (which defines, e.g., viaduct.engine.runtime) contains the implementation of that project’s API. This code structure relates to our architecture as follows:\nA diagram of Viaduct’s source code structure.\n(Note that, to reduce possible confusion by tenant developers, who use the tenant domain’s api package directly, types defined by the tenant api project are in the viaduct.api package hierarchy rather than in viaduct.tenant.api.)\nAs this diagram is meant to imply, consumers of a domain consume it through the types in its api project. They do not take direct dependencies on runtime projects. However, those consumers do need factories and other mechanisms to create instances of the api types. These are found in a domain’s wiring project. In Gradle, a domain’s wiring project takes an API dependency on the domain’s api project, and an implementation dependency on its runtime project. Consumers of the engine and service domains take an implementation dependency on their respective wiring projects - which will pull in their APIs as a compile-time dependency.\nThe tenant module domain is a little different. Tenant developers never instantiate tenant.api types directly, rather instances of those types get passed via SPIs. Thus, there is no wiring project for the tenant domain. However, that domain does have a bootstrap project, which is intended to be used by Service Engineers to bootstrap the tenant developer API. (This bootstrap project plays a similar role as the wiring project for the other domains, i.e., a mechanism to create instances. However, where wiring projects create instances of types in their respective api domains, the tenant bootstrap project creates instances of the engine’s SPI (in particular, TenantAPIBootstrapper). To avoid confusion, we’ve used a different name.)\nDetailed dependencies:\nA diagram of dependencies between Viaduct’s source code modules.\nThe dotted lines represent an indirect dependency accomplished via the wiring project. The idea is that the three api projects are leaves in our dependency tree; the service and tenant domains access the engine implementation through its wiring project. The engine gets passed implementations of viaduct.service.api.spi interfaces via the viaduct.services.api.Viaduct builder, and it in turn passes those into the tenant runtime via the engine’s SPI classes. (This is where we want to be, it’s not where we are today - there are quite a few violations that we are working to clean up.)\n","categories":"","description":"Guided tour of the Viaduct architecture.","excerpt":"Guided tour of the Viaduct architecture.","ref":"/viaduct/docs/contributors/architecture/","tags":"","title":"Architecture"},{"body":"Code StructurePackagesThere are three main packages in particular making up the Tenant API:\nviaduct.api: These are classes like FieldExecutionContext which are the foundation of our tenant developer API.\nviaduct.api.grts: This is where we put generated code for classes used to represent GraphQL types, see description of GRTs below.\n\u003cmodule-prefix\u003e.resolverbases: This is where we put generated base classes to be inherited by resolver classes (more on these shortly).\n","categories":"","description":"Tenant API Code Structure","excerpt":"Tenant API Code Structure","ref":"/viaduct/docs/developers/generated_code/code_structure/","tags":"","title":"Code Structure"},{"body":" Preview Feature This feature is currently in development. All documented functionality is ready to use but the API may change in future releases. Data Fetcher Error HandlingViaduct provides two extension points for customizing error handling in resolvers. Both are optional for service architects.\nResolverErrorBuilderWhen a resolver throws an exception, Viaduct will catch it and return it as a GraphQL error. As a service architect, you can customize resolver exception handling by implementing your own ResolverErrorBuilder . This interface has a single method, exceptionToGraphQLError, which takes the thrown exception and constructs a GraphQLError object.\nResolverErrorBuilder is an interface with a single method, exceptionToGraphQLError. This method produces a list of GraphQLError objects.\nimport graphql.GraphqlErrorBuilder class MyResolverErrorBuilder : ResolverErrorBuilder { override fun exceptionToGraphQLError( exception: Throwable, env: DataFetchingEnvironment, errorMetadata: ErrorMetadata ): List\u003cGraphQLError\u003e { return when (exception) { is MyCustomException -\u003e listOf( GraphqlErrorBuilder.newError(env) .message(\"A custom error occurred: ${exception.customMessage}\") .build() ) else -\u003e listOf( GraphqlErrorBuilder.newError(env) .message(\"An unexpected error occurred\") .errorType(ErrorType.DataFetchingException) .build() ) } } } ResolverErrorReporterIn addition to returning errors in ExecutionResult, Viaduct also provides allows you to configure an error reporter called from within the engine.\nResolverErrorReporter is an interface with a single method, reportError. This method is called whenever a resolver throws an exception and allows you to log the error or send it to an external monitoring system. This interface does not affect error reporting to clients or handling within the Viaduct engine.\nFor instance, if you wanted to emit exceptions to Sentry, you could implement the interface like this:\nimport graphql.schema.DataFetchingEnvironment import graphql.schema.GraphQLFieldDefinition class MyResolverErrorReporter : ResolverErrorReporter { override fun reportError( exception: Throwable, fieldDefinition: GraphQLFieldDefinition, env: DataFetchingEnvironment, errorMessage: String, errorMetadata: ErrorMetadata ) { Sentry.captureException(exception) { it.setExtra(\"fieldName\", fieldDefinition.name) it.setExtra(\"parentType\", fieldDefinition.type.name) it.setExtra(\"path\", env.executionStepInfo.path.toString()) it.setExtra(\"errorMessage\", errorMessage) it.setExtra(\"errorMetadata\", errorMetadata.toString()) } } } ResolverErrorReporter provides information about the exception, allowing you to include additional context about the error in your monitoring system. The example above includes the field name, parent type, execution path and error metadata.\n","categories":"","description":"Monitoring and returning errors in Viaduct.","excerpt":"Monitoring and returning errors in Viaduct.","ref":"/viaduct/docs/service_engineers/observability/error_handling/","tags":"","title":"Error Handling"},{"body":"SchemaAll schema fields with the @resolver directive have a corresponding field resolver. This directive can only be placed on object, not interface fields.\nIn this example schema, we’ve added @resolver to the displayName field:\ntype User implements Node { id: ID! firstName: String lastName: String displayName: String @resolver } When to use @resolverField resolvers are typically used in the following scenarios:\nFields with arguments should have their own resolver, since resolvers don’t have access to the arguments of nested fields:\naddress(format: AddressFormat): Address @resolver Fields that are backed by a different data source than the core fields on a type should have their own resolver. In the example below, suppose the resolver for wishlists is backed by a Wishlist service endpoint, whereas firstName and lastName are backed by a User service endpoint:\nfirstName: String lastName: String wishlists: [Wishlist] @resolver This avoids executing the wishlists resolver and calling the Wishlist service if the field isn’t in the client query.\nFields that are derived from other fields, such as the displayName example shown in more detail below, which is derived from firstName and lastName. Although this example is simple, in practice there can be complex resolvers that have large required selection sets. This keeps the logic for these fields contained in their own resolvers which is easier to understand and maintain.\nGenerated base classViaduct generates an abstract base class for all schema fields with the @resolver directive. For User.displayName, Viaduct generates the following code:\nobject UserResolvers { abstract class DisplayName { open suspend fun resolve(ctx: Context): String? = throw NotImplementedError() open suspend fun batchResolve(contexts: List\u003cContext\u003e): List\u003cFieldValue\u003cString?\u003e\u003e = throw NotImplementedError() class Context: FieldExecutionContext\u003cUser, Query, NoArguments, NotComposite\u003e } // If there were more User fields with @resolver, their base classes would be generated here } The nested Context class is described in more detail below.\nImplementationImplement a field resolver by subclassing the generated base class, and overriding exactly one of either resolve or batchResolve. Learn more about batch resolution here.\nLet’s look at the resolver for User.displayName:\n@Resolver( \"fragment _ on User { firstName lastName }\" ) class UserDisplayNameResolver : UserResolvers.DisplayName() { override suspend fun resolve(ctx: Context): String? { val fn = ctx.objectValue.getFirstName() val ln = ctx.objectValue.getLastName() return when { fn == null \u0026\u0026 ln == null -\u003e null fn == null -\u003e ln ln == null -\u003e fn else -\u003e \"$fn $ln\" } } } As this example illustrates, the @Resolver annotation can contain an optional fragment on the parent type of the field being resolved. We call this fragment the required selection set of the resolver. In this case, the required selection set asks for the firstName and lastName fields of User, which are combined to generate the user’s display name. If a resolver attempts to access a field that’s not in its required selection set, an UnsetSelectionException is thrown at runtime.\nThe @Resolver annotation can also be used to declare data dependencies on the root Query type. Learn more about the annotation here.\nImportant clarification: there are no requirements on the names of these resolver classes: We use UserDisplayNameResolver here as an example of a typical name, but that choice is not dictated by the framework.\nContextBoth resolve and batchResolve take Context objects as input. This class is an instance of FieldExecutionContext :\ninterface FieldExecutionContext\u003cT: Object, Q: Query, A: Arguments, O: CompositeOutput\u003e: ResolverExecutionContext { val objectValue: T val queryValue: Q val arguments: A fun selections(): SelectionSet\u003cO\u003e } objectValue gives access to the object that contains the field being resolved. Fields of that object can be accessed, but only if those fields are in the resolver’s required selection set. If the resolver tries to access a field not included within its required selection set, it results in an UnsetSelectionException at runtime.\nqueryValue is similar to objectValue, but applies to the root query object of the Viaduct central schema. Like objectValue, fields on queryValue can only be accessed if they are in the resolver’s required selection set.\narguments gives access to the arguments to the resolver. When a field takes arguments, the Viaduct build system will generate a GRT representing the values of those arguments. If User.displayName took arguments, for example, Viaduct would generate a type User_DisplayName_Arguments having one property per argument taken by displayName. In our example, the field execution context for displayName is parameterized by the special type NoArguments indicating that the field takes no arguments.\nselections() returns the selections being requested for this field in the query, same as the selections function for the node resolver. The SelectionSet type is parameterized by the type of the selection set. For example, in the case of User’s node resolver, selections returned SelectionSet\u003cUser\u003e. In the case of displayName, selections returns SelectionSet\u003cNotComposite\u003e, where the special type NotComposite indicates that displayName does not return a composite type (it returns a scalar instead).\nSince NodeExecutionContext implements ResolverExecutionContext , it also includes the utilities provided there, which allow you to:\nExecute subqueries Construct node references Construct GlobalIDs Responsibility setFor scalar and enum fields like displayName, the field resolver is just responsible for resolving the single field. If the field has a node type, the field resolver constructs a node reference using just the node’s GlobalID, which tells the engine to run the node resolver. For fields with non-node object types, the field resolver is responsible for all nested fields without its own resolver.\n","categories":"","description":"Writing resolvers for fields in Viaduct","excerpt":"Writing resolvers for fields in Viaduct","ref":"/viaduct/docs/developers/resolvers/field_resolvers/","tags":"","title":"Field Resolvers"},{"body":"Both node resolvers and field resolvers can be implemented using the batchResolve function. This provides an alternative to the widely used data loader pattern.\nThe N+1 problemConsider this example schema:\ntype Query { recommendedListings: [Listing] @resolver } type Listing implements Node { id: ID! title: String } Suppose the query below returns 3 recommended listings. A Listing node resolver that makes a call to a listings service to fetch a single listing in the resolve function will result in 3 separate calls to the service.\nquery { recommendedListings { id title } } This is the N+1 problem, which is commonly solved by implementing a data loader that batches calls to the listings service. The resolver calls the data loader, which then calls the data source.\nbatchResolveIn Viaduct, you can implement the batchResolve function and directly call the data source instead of going through a data loader. Under the hood, Viaduct still uses a data loader to batch requests. However, this data loader is part of Viaduct’s framework, not something that application developers need to write and maintain. Here’s an example Listing batch node resolver:\n@Resolver class ListingNodeResolver @Inject constructor(val client: ListingClient) : NodeResolvers.Listing() { override suspend fun batchResolve(contexts: List\u003cContext\u003e): List\u003cFieldValue\u003cListing\u003e\u003e { val listingIDs = contexts.map { it.id.internalID } val responses = client.fetch(listingIDs) return contexts.map { ctx -\u003e val listingID = ctx.id.internalID val response = responses[listingID] FieldValue.ofValue( Listing.Builder(ctx) .title(response.title) .build() ) } } } InputbatchResolve takes a list of Context objects as input. This is the same Context object type passed to the non-batching resolve function. Viaduct’s GraphQL execution engine batches these contexts before passing them to the batchResolve function.\nOutputThe list that batchResolve returns must have the same number of elements as the input list. Each output value corresponds to the input Context at the same list index.\nFieldValueNotice that the output list elements are wrapped in FieldValue (e.g., List\u003cFieldValue\u003cListing\u003e\u003e in the example above). This represents either a successfully resolved value or an error value.\nUsage:\nFieldValue.ofValue(v): constructs a successfully resolved value, as shown in the example above FieldValue.ofError(e): constructs an error value, where e is an exception. The corresponding value in the GraphQL response will be null, and there will be an error in the errors array. When to use batchResolveOverride batchResolve whenever you need to fetch data from an external data source that supports batch loading. This solves the N+1 problem and similar issues where multiple parts of a GraphQL query fetch data that can be batched together.\nIf your resolver does not have external data dependencies, there is generally no benefit to implementing batchResolve.\nThose familiar with data loaders may know that they also provide an intra-request cache. In Viaduct, this memoization cache is decoupled from batching, so you do not need to implement batchResolve for caching purposes.\n","categories":"","description":"Batch node and field resolvers","excerpt":"Batch node and field resolvers","ref":"/viaduct/docs/developers/resolvers/batch_resolution/","tags":"","title":"Batch Resolution"},{"body":"Field resolvers must be annotated with @Resolver to be registered. This annotation class also allows resolvers to declare data dependencies in the form of required selection sets via objectValueFragment and queryValueFragment:\nannotation class Resolver( @Language(\"GraphQL\") val objectValueFragment: String = \"\", @Language(\"GraphQL\") val queryValueFragment: String = \"\", val variables: Array\u003cVariable\u003e = [] ) objectValueFragment: a GraphQL fragment on the object type that contains the field being resolved. In the User.displayName example below, the fragment must be on the User type.\nqueryValueFragment: a GraphQL fragment on the root query type.\nvariables: values of variables used in objectValueFragment or queryValueFragment.\nRequired selection set syntaxA resolver can optionally specify one or both of objectValueFragment and queryValueFragment using either the shorthand fragment syntax, or full fragment syntax. Values can be accessed using Context.objectValue and Context.queryValue.\nShorthand syntaxThe shorthand fragment syntax just includes the selections within the fragment body.\nHere’s an example of what this looks like for a User.displayName field. The selections must be on the User type:\n@Resolver(\"firstName lastName\") class UserDisplayNameResolver : UserResolvers.DisplayName() The shorthand fragment syntax can also be used for queryValueFragment. The selections must be on the root query type:\n@Resolver(queryValueFragment = \"user { firstName lastName }\") Full fragment syntaxThe full fragment syntax is the regular GraphQL fragment syntax. You can name the fragment whatever you’d like, although we typically use _ for the fragment name when there’s only a single fragment to indicate that the name isn’t used anywhere:\n@Resolver(\"fragment _ on User { firstName lastName }\") You can define multiple named fragments and reference them within your main fragment:\n@Resolver( queryValueFragment = \"\"\" fragment _ on Query { listing { cover: coverImage { ...ImageDetails } rooms { images { ...ImageDetails } } } } fragment ImageDetails on Image { url caption } \"\"\" ) Note that if you have multiple fragments on the type of the main fragment (either the object type or the query type), the primary one needs to be named Main:\n@Resolver( \"\"\" fragment Main on User { firstName lastName ...UserProfilePhoto } fragment UserProfilePhoto on User { profilePhoto { url caption } } \"\"\" ) Accessing required selection set valuesYou can access the required selection set values via the Context object given as input to the field resolver. Context.objectValue and Context.queryValue are GRTs of the object and Query types, e.g.\nctx.objectValue.getFirstName() ctx.queryValue.getListing().getCoverImage(alias = \"cover\") If the resolver tries to access a field not included within its required selection set, it results in an UnsetSelectionException at runtime.\nIn the Kotlin API, each of the field getters are suspend functions. Your resolver may begin execution before the selections have been fully resolved via their corresponding resolvers. If that happens, the field getter will suspend until the field is resolved.\nVariablesThe fragments in @Resolver annotations can contain variables. These variables can be bound to values in one of two ways:\nVia the variables parameter in @Resolver Via the resolver’s variable provider @Resolver variables parameterVariables may be bound using the variables parameter of @Resolver, which is an array of @Variable annotations. For example, consider this resolver configuration for the field MyType.foo that takes an argument include:\n@Resolver( objectValueFragment = \"\"\" fragment _ on MyType { field @include(if: ${'$'}shouldInclude) } \"\"\", variables = [Variable(\"shouldInclude\", fromArgument = \"includeMe\")] ) This resolver fragment uses a shouldInclude variable. At runtime, the value for this variable will be determined by the value of the includeMe argument to MyType.foo. To support nested GraphQL input types, the fromArgument string can contain a dot-separated path.\nThere are three mutually-exclusive parameters to the @Variable class that can be used to set the value of a variable:\nthe fromArgument parameter just illustrated the fromObjectField parameter, which takes a dot-separated path relative to the objectValue of an execution. If used, the path must be a selection defined in the resolver’s objectValueFragment. the fromQueryField parameter. This parameter is analogous to fromObjectField, but the path describes a selection in the resolver’s queryValueFragment. VariablesProviderThe variables parameter does not allow arbitrarily-computed values to be used as variables. To support dynamic use cases, a VariablesProvider can be used.\nFor example, consider a resolver for MyType.foo whose required selection set uses variables named startDate and endDate. To provide dynamically-computed values for these variables, the implementation for MyTypeResolvers.Foo may nest a class that implements the VariablesProvider interface:\n@Variables(types = \"startDate: Date, endDate: Date\") class Vars : VariablesProvider\u003cMyType_Foo_Arguments\u003e { override suspend fun provide(args: MyType_Foo_Arguments) = LocalDate.now().let { mapOf( \"startDate\" to it, \"endDate\" to it.plusDays(7) ) } } } The value of the types parameter to @Variables must conform to VariableDefinitionlist from GraphQL Spec. The args parameter to the provide function is the arguments of the field whose resolver class defines this variable provider, or NoArguments if the field takes no arguments.\n","categories":"","description":"Using the @Resolver annotation","excerpt":"Using the @Resolver annotation","ref":"/viaduct/docs/developers/resolvers/resolver_annotation/","tags":"","title":"Resolver Annotation"},{"body":"GraphQL resolvers frequently need to link to other Node types in the graph. Consider this example, where a Listing type has an edge to its host user:\ntype Listing implements Node { id: ID! host: User ... } type User implements Node { id: ID! ... } Rather than requiring the Listing resolver to also be responsible for resolving User data, the Listing resolver can use Context.nodeFor() to create a node reference. The nodeFor function takes a GlobalID as input and returns a special GRT for that node:\n@Resolver class ListingNodeResolver @Inject constructor(val client: ListingClient) : NodeResolvers.Listing() { override suspend fun resolve(ctx: Context): Listing { val data = client.fetch(ctx.id.internalID) val hostGlobalID = ctx.globalIDFor(User.Reflection, data.hostID) // Creates a node reference as a User GRT val host = ctx.nodeFor(hostGlobalID) return Listing.builder(ctx) .host(host) /* ... other fields populated from [data] */ .build() } } When this resolver returns, the Viaduct engine will invoke the User node resolver, as well as any field resolvers on the User type, to fetch data for the Listing.host field.\nThis example illustrates a subtle aspect of the “responsibility set” of resolvers, which is that the responsibility for resolving a field with a node type is split between the resolver whose responsibility set contains the field, and the resolver of the node being returned. Specifically, the containing resolver is responsible for resolving the node’s id field and returning a node reference as illustrated here. From there, the node resolver takes over to resolve the rest of the node’s responsibility set.\nWe noted above that the GRT returned by nodeFor is “special.” It’s special because, in the code that calls nodeFor, only the id field is set; all other fields are not set and will throw an exception on an attempt to read them. If for some reason a resolver needs a resolved node rather than a node reference, the resolver can use a subquery.\n","categories":"","description":"Creating node references in resolvers","excerpt":"Creating node references in resolvers","ref":"/viaduct/docs/developers/resolvers/node_references/","tags":"","title":"Node References"},{"body":"Context.query can be used to execute a subquery, i.e., a GraphQL query operation rooted in the full-schema’s Query root type. As an example, we can modify the resolver for User.displayName to incorporate data that it loads from Query:\n@Resolver( \"fragment _ on User { id firstName lastName }\" ) class UserDisplayNameResolver: UserResolvers.DisplayName() { override suspend fun resolve(ctx: Context): String? { val id = ctx.objectValue.getId() val fn = ctx.objectValue.getFirstName() val ln = ctx.objectValue.getLastName() // determine if user is the logged-in user, in which case // we add a suffix to their displayName // first, construct a selection set on the Query object val querySelections = ctx.selectionsFor( Query.Reflection, \"{ viewer { user { id } } }\" ) // second, load the selections on Query val query = ctx.query(querySelections) val isViewer = id == query.getViewer()?.getUser()?.getId() val suffix = if (isViewer) \" (you!)\" else \"\" return when { fn == null \u0026\u0026 ln == null -\u003e null fn == null -\u003e ln ln == null -\u003e fn else -\u003e \"$fn $ln$suffix\" } } } We call this process of loading a selection set an “imperative subquery”, which is distinguished from the more “declarative” method of data loading used by the @Resolver annotation. It can be used to load selections on the root Query object that are not known until runtime.\n","categories":"","description":"Executing subqueries in resolvers","excerpt":"Executing subqueries in resolvers","ref":"/viaduct/docs/developers/resolvers/subqueries/","tags":"","title":"Subqueries"},{"body":"Mutation fields should use the @resolver directive to provide a field resolver that executes the mutation. For the following example schema:\nextend type Mutation { publishListing(id: ID! @idOf(type: \"Listing\")): Listing @resolver } The resolver might look like:\n@Resolver class PublishListingResolver @Inject constructor( val client: ListingServiceClient ) : MutationResolvers.PublishListing() { override suspend fun resolve(ctx: Context): Listing { client.publish(ctx.arguments.id.internalID) return ctx.nodeFor(ctx.arguments.id) // Creates a Listing node reference } } As this example shows, resolvers for mutation fields are almost identical to query field resolvers. A major difference is that Context implements MutationFieldExecutionContext. This allows mutation field resolvers to execute submutations using Context.mutation() in addition to executing subqueries using Context.query().\nMutation field resolvers should still be annotated with @Resolver. However, they may not provide a required selection set using objectValueFragment, since those selections would include other mutation fields. Mutation field resolvers can execute other mutation fields by calling Context.mutation() instead.\n","categories":"","description":"Mutating data in Viaduct","excerpt":"Mutating data in Viaduct","ref":"/viaduct/docs/developers/resolvers/mutations/","tags":"","title":"Mutations"},{"body":"","categories":"","description":"Developing tenant modules in Viaduct.","excerpt":"Developing tenant modules in Viaduct.","ref":"/viaduct/docs/developers/","tags":"","title":"Developers"},{"body":"In Viaduct, all module code is provided in the form of either a node resolver or a field resolver. Node and field resolvers are implemented similarly:\nSchema: The schema is the source of truth for what resolvers should exist. Define node types and add the @resolver directive to fields you want to provide resolvers for. Generated base classes: Viaduct generates abstract classes for all node and field resolvers based on the schema. Implementation: Implement a resolver by providing a subclass of the generated base class and overriding either resolve or batchResolve. Responsibility setsResponsibility sets (also known as “responsibility selection sets”) are an important concept in the Viaduct API. Every node and field resolver is responsible for resolving the fields in its responsibility set. This includes all fields, including nested fields, that themselves do not have a resolver. The node and field resolver pages provide more details with examples.\nInjectionViaduct is designed to create instances of resolver classes through dependency injection. You can define this behavior by implementing this interface:\ninterface TenantCodeInjector { fun \u003cT\u003e getProvider(clazz: Class\u003cT\u003e): Provider\u003cT\u003e } Examples of using this dependency injection mechanism are available in the demo applications.\nIf you do not provide an implementation of TenantCodeInjector , Viaduct will use a naive default implementation that assumes a zero-argument constructor is available for all resolvers. Whenever the GraphQL execution engine needs to invoke a resolver, it will use this to construct an instance of the resolver. While sufficient for toy applications, we strongly suggest using a dependency injection framework for real applications.\n","categories":"","description":"Understanding resolvers in Viaduct","excerpt":"Understanding resolvers in Viaduct","ref":"/viaduct/docs/developers/resolvers/","tags":"","title":"Resolvers"},{"body":"MetricsViaduct provides built-in metrics on fields, field resolvers, node resolvers and access checkers (“measured entities”). These metrics are focused on latency, error rates and attribution. Viaduct offers observability to support the following use cases:\nLatency Determine latency (across various percentiles) in aggregate for measured entities Figure out the sequence of executions of measured entities happening in a given request that is contributing to latency (critical path) Understand why each measured entity is getting called / executed Attribute each measured entity running in a request to a specific tenant module Error Rate Monitor fail states of operations (either partial or full failure) on Viaduct What is the error rate for a given operation? If the error rate is greater than zero, what ‘measured entities’ are causing the error? What is the cause? Understand what is causing each operation failure Errors are attributable to the responsible ‘measured entity’(field or resolver) that triggered the exception Errors in resolvers should propagated to the field that resulted in the resolver being called Be able to find exception stack trace (when applicable) Monitor operation for error rate Errors are eventually propagated to the top level operation to signify if the operation failed or not AttributionDue to the async nature of Viaduct’s execution strategy and use of caching, this requires special callout. Viaduct’s observability supports the following use cases:\nDevelopers are able to understand why their field is slow and to attribute the slowness to a specific measure entity. For example, the writer of a DerivedFieldProvider wants to understand why their field is slow. Developers are able to understand why an error is thrown and attribute the error to a specific code component. Similarly as the above example, we need a way to help DFP B understand how field A errors are impacting its execution. Developers are also able to understand what code component triggered the fetch for their field, and what the frequency is for the fetch. If taking the above example, field A should be able to know DFP B triggers its fetch and the frequency of the fetch. Available Metrics viaduct.execution Full execution lifecycle metric which measures end-to-end execution time for the entire GraphQL request Measurements: Latency (p50, p75, p90, p95) and count Tags: operation_name: GraphQL operation name (if available) success: true if no throwable and data is present, false otherwise viaduct.operation Operation-level metric which measures the time to execute the specific GraphQL operation Measurements: Latency (p50, p75, p90, p95) and count Tags: operation_name: GraphQL operation definition name (if available) viaduct.field Field-level metric which measures the time to fetch/resolve individual GraphQL fields Measurements: Latency (p50, p75, p90, p95) and count Tags: operation_name: GraphQL operation name (if available) field: Field path in format ParentType.fieldName or just fieldName for root fields success: true if no exception thrown during field fetch, false otherwise ","categories":"","description":"Monitoring and Logging in Viaduct","excerpt":"Monitoring and Logging in Viaduct","ref":"/viaduct/docs/service_engineers/observability/","tags":"","title":"Observability"},{"body":"","categories":"","description":"Operating a Viaduct instance.","excerpt":"Operating a Viaduct instance.","ref":"/viaduct/docs/service_engineers/","tags":"","title":"Service Engineers"},{"body":"Unit Testing ResolversResolver unit tests can extend ViaductResolverTestBase, which provides utilities for mocking ExecutionContext and handles injection. In order to test a resolver, inject it into the test class, and then call its resolve function in your test case with a ExecutionContext constructed using ViaductResolverTestBase.contextForResolver(...).\n","categories":"","description":"Testing Tenant Module Code","excerpt":"Testing Tenant Module Code","ref":"/viaduct/docs/developers/testing/","tags":"","title":"Testing"},{"body":"Viaduct uses two different Kotlin types to represent GraphQL ID types: GlobalID\u003cT\u003e and String. GlobalID is an object that consists of a type and an internal ID. They are used to uniquely identify node objects in the graph. GlobalID values support structural equality, as opposed to referential equality.\nThere are two conditions under which GlobalID\u003cT\u003e will be used:\nThe id field of a Node object type A field of type ID with the @idOf(type:\"T\") directive, where T must be a GraphQL object or interface type that implements Node Elsewhere in the Kotlin code, String will be used for IDs.\nFor the examples below, id, id3 and f2 are GlobalIDs and while id2 and f1 are Strings.\ntype MyNode implements Node { id: ID! id2: ID! id3: ID! @idOf(type: \"MyNode\") } input Input { f1: ID! f2: ID! @idOf(type: \"MyNode\") } If a Node object type implements an interface, and that interface has an id field, then that interface must also implement Node.\nInstances of GlobalID can be created using the Context objects provided to resolvers, e.g., ctx.globalIDFor(User.Reflection, \"123\").\n","categories":"","description":"Global identifiers for nodes","excerpt":"Global identifiers for nodes","ref":"/viaduct/docs/developers/globalids/","tags":"","title":"Global IDs"},{"body":"ScopesThis document provides an overview on how to define scopes on the Viaduct GraphQL schema.\nThe scoop on scopesIn order to make schema visibility control more explicit and intuitive, we introduced Scopes.\nScopes are a mechanism for encapsulating parts of your schema for information-hiding purposes. Two commonly-used scopes are viaduct, which has a bigger schema available to all of your internal systems, and viaduct:public, a smaller schema available publicly to your frontend clients. Almost all data types will have viaduct scope, which allows them to be queried by backend clients. Some data types, or a subset of fields within data types that can be queried by frontend clients, also have the viaduct:public scope.\nScopes leverage GraphQL type extensions to separate fields within a type that belong to different scopes. This convention avoids the need for annotating each field in the schema with @scope directives, and provides a way to separate different types of fields in the SDL to optimize for human readability.\nFor example, if we are to expose only field1 from Foo to viaduct:public but not field2 or field3, we will organize our schema like this:\ntype Foo @scope(to: [\"viaduct\", \"viaduct:public\"]) { field1: Bar } extend type Foo @scope(to: [\"viaduct\"]) { field2: Int field3: String } type Bar @scope(to: [\"viaduct\", \"viaduct:public\"]) { field4: Boolean field5: String } As you will also learn from the later sections, the scope validation system will also enforce explicitness so that each type (including object, input, interface, union, and enum) and their extensions will always have at least one scope value.\n[alert]\nEither nothing is scoped or everything has a scope applied to it. There is no default scope.\n[/alert]\nMultiple SchemasA single instance of the Viaduct framework can expose multiple schemas. Within Airbnb, for instance, the Viaduct service itself, exposes a different, more complete schema to internal clients than it exposes to external Web and mobile clients. Scopes also provide encapsulation that allows us to hide implementation details present in your central schema.\nEvery schema exported by an instance of the Viaduct framework is called a scope set. A scope set is identified by a schema ID. The particular scope set seen by a given request to the Viaduct framework is controlled by the schemaId field of ExecutionInput . In the above example, viaduct and viaduct:public are both schema IDs. You can use as many schema IDs as you like with whatever naming scheme fits your use case.\nGuidelines for annotating types with @scopeAlways append @scope to the main typeWhenever you are creating a new type (including object type, input type, interface, union, and enum), always append @scope(to: [\"scope1\", \"scope2\", ...]) to the type itself. (Replace \"scope1\", \"scope2\", etc. with your desired scopes)\nAll the attributes within the main type will share and be exposed to ALL the scopes defined in the @scope values.\n# field1 and field2 will be visible to both Viaduct data API and public API type Foo @scope(to: [\"viaduct\", \"viaduct:public\"]) { field1: Int field2: String } # CONSTANT1 and CONSTANT2 will be visible to Viaduct data API, as well as both foo and bar. enum Bar @scope(to: [\"viaduct\", \"foo\", \"bar\"]) { CONSTANT1 CONSTANT2 } # field from Baz is only visible to Viaduct data API input Baz @scope(to: [\"viaduct\"]) { field: Boolean } Create type extensions and move fields with narrower scopes to this extensionIf you need to limit the visible scopes for certain fields, create a type extension, move those fields over, and append @scope with proper scopes.\nFor example, the following definition will expose field3 to private only.\ntype Foo @scope(to: [\"public\", \"private\"]) { field1: Int field2: String } extend type Foo @scope(to: [\"private\"]) { field3: Boolean } ValidationIn GraphQL SDL, scopes are referenced by their string value, and in Kotlin are referenced by the strongly typed enum member. The SDL will be validated at build time to ensure invalid scope names were not referenced.\nIn addition to detecting invalid scope names, the Viaduct Bazel validators will perform other static analysis on the schema in order to detect invalid or confusing scope usage.\nDetecting inaccessible fields when referencing another typeStatic analysis tooling will detect @scope usages that cause inaccessible fields. Take the following schema excerpt:\ntype User @scope(to: [\"scope1\",\"scope2\"]) { id: ID! firstName: String lastName: String } type Listing @scope(to: [\"scope3\"]) { user: User # this field would never be accessible } In the above example, the User type is only available in the scope1 and scope2 scopes, and the Listing type is only available in the scope3 scope. The user field in Listing is of type User, but User is not visible to the scopes associated with the Listing type. Thus, filtering the schema to any of the three scopes used in this schema excerpt would result in the user field within Listing being filtered out of the schema.\nThis invariant can be corrected in two ways:\nThe Listing type’s scope should be modified to include scope1 or scope2, OR The User type’s scope should be modified to include the scope3 scope. Auto prune a type when all of its fields are out of scopeWhen all the fields of a type are out of scope, this type will not be accessible, even if it is within the scope. Therefore, Viaduct prunes such empty types recursively in the generated schema. For example:\ntype StaySpace @scope(to: [\"viaduct\", \"listing-block\", \"viaduct:private\"]) { spaceId: Long metadata: SpaceMetadata } type SpaceMetadata @scope(to: [\"viaduct\", \"listing-block\"]) { bathroom: StayBathroomMetadata bedroom: StayBedroomMetadata } type StayBathroomMetadata @scope(to: [\"viaduct\", \"viaduct:private\"]) { spaceName: String } type StayBedroomMetadata @scope(to: [\"viaduct\", \"viaduct:private\"]) { spaceName: String } Filtering the above schema excerpt to listing-block will make SpaceMetadata an empty type, since both StayBathroomMetadata and StayBedroomMetadata will not be in the scope. Thus, SpaceMetadata attribute will be pruned from StaySpace in the listing-block scope, as it will not be reachable, despite that this type has annotated with listing-block scope.\nDetect invalid scope usage within a typeWhen leveraging a type extension to define fields that are available in a specific scope, it’s essential that the scope specified in the directive on the type extension be one of the scopes specified in the original definition of the type.\nTake for example the following schema excerpt:\ntype User @scope(to: [\"viaduct\",\"user-block\"]) { id: ID! firstName: String lastName: String } extend type User @scope(to: [\"viaduct:internal-tools\"]) { aSpecialInternalField: String } This example shows an incorrect usage of the scope directive on the type extension, as the viaduct:internal-tools scope is not specified as a scope on the original User type definition.\nThe correct version of the above example would be:\ntype User @scope(to: [\"viaduct\",\"viaduct:internal-tools\", \"user-block\"]) { id: ID! firstName: String lastName: String } extend type User @scope(to: [\"viaduct:internal-tools\"]) { aSpecialInternalField: String } This validation rule enforces the convention that common fields be defined in the original type definition, and fields that are defined in specific scopes be specified using type extensions.\nTroubleshootingIf you get an error like Unable to find concrete type ... for interface ... in the type map or Unable to find concrete type ... for union ... in the type map, it’s because the interface or union type is defined in schema module A, and the concrete type that implements the interface or extends the union is defined in schema module B, and B does not depend on A.\nFor example, this is not allowed because UnionA is defined in the data module and its member TypeA is defined in the entity module. The entity module does not depend on the data module.\n# modules/entity type TypeA { fieldA: String } # modules/data type TypeB { fieldB: String } union UnionA = TypeB extend UnionA = TypeA # \u003c-- not ok To fix it, make sure you define the concrete type of interface or union in a schema module that is dependent on the schema module where the interface or union type is defined.\nFor example, you can “lift” up the type definition for UnionA to the entity module:\n# modules/entity type TypeA { fieldA: String } union UnionA = TypeA # modules/data type TypeB { fieldB: String } extend type UnionA = TypeB # \u003c-- ok ","categories":"","description":"Schema visibility and access control in Viaduct.","excerpt":"Schema visibility and access control in Viaduct.","ref":"/viaduct/docs/developers/scopes/","tags":"","title":"Scopes"},{"body":"","categories":"","description":"Documentation for contributing to Viaduct.","excerpt":"Documentation for contributing to Viaduct.","ref":"/viaduct/docs/contributors/","tags":"","title":"Contributors"},{"body":"GraphQL Representational Type (GRT)The API generates two kinds of classes: GraphQL Representational Types (GRTs), and resolver base classes, described in the Resolvers section.\nFor each GraphQL type, Viaduct generates a number of Kotlin classes to represent its values. These classes are found in the viaduct.api.grts package. We generate two classes for each GraphQL type: a class representing a value of a given type, and a builder-class allowing you to construct a value of a given type. Consider this simple schema:\ntype User implements Node { id: ID! firstName: String lastName: String displayName: String } The signature of the GRT for this type would look approximately like this:\npackage viaduct.api.grts class User private constructor(...): NodeObject { suspend fun getId(alias: String? = null): GlobalID\u003cUser\u003e suspend fun getFirstName(alias: String? = null): String? suspend fun getLastName(alias: String? = null): String? suspend fun getDisplayName(alias: String? = null): String? class Builder(ctx: ExecutionContext): DynamicValueOutputBuilder\u003cUser\u003e { fun id(id: GlobalID\u003cUser\u003e): Builder fun firstName(firstName: String?): Builder fun lastName(lastName: String?): Builder fun displayName(displayName: String?): Builder override fun build(): User } } NodeObject is a tagging interface (i.e., an interface with no methods) for GRTs representing GraphQL object types. DynamicValueOutputBuilder is an interface for builders of such types (it is parameterized on T and defines a build function that returns a T).\nThe values from a fragment on User (for example) are accessed through the GRT for User. As a result, the Viaduct GRTs for object types distinguish fields that are “not set,” because they haven’t been requested for in the fragment, from fields that are in the fragment and thus are “set.” If you attempt to access a field that has not been set, a UnsetSelectionException exception will be thrown, even if that field is nullable. Also, when you build an object-type value, you do not have to set all fields, even if those fields are non-nullable.\nThe GRTs for interface types are Kotlin interfaces with suspending getters (but no builders), while the GRTs for union types are simply Kotlin “tagging” interfaces (i.e., Kotlin interfaces with no members).\nFor GraphQL input-object types, the pattern for GRTs is similar to that for output-object types illustrated by User. However, instead of suspending getter functions, the GRTs for input-object types use Kotlin properties for accessing fields. “Partial” input-object types are not possible: every field of an input-object GRT instance is defined (thus, UnsetSelectionException is never thrown when accessing their fields). To achieve this invariant, builders for input-object types are stricter than those for object types: if you call build on an InputType.Builder instance without having set all required fields of that type, then build will raise a runtime error. A field is “required” if it’s defined with the `!` (non-null) wrapper and it has no default value.\nViaduct is what is known as a “schema-first” GraphQL system: developers write GraphQL schema directly, and the Viaduct system generates “GraphQL representational types (GRTs)” to allow developers to read and write the types expressed by the schema.\nAny single tenant module consumes only a small fraction of the central schema, so building representational types for the entire schema for every tenant is wasteful. Instead, Viaduct uses “compilation schemas”, a per-tenant-module, private view of the central schema consisting of only the schema elements used by a tenant module. This makes Viaduct builds fast and scalable by ensuring that tenant modules are built in parallel and are only rebuilt when needed.\nThe tenant module compilation schema is used to generate the GRTs described above. The compilation schema is a subset of the total schema visible to a tenant module, a subset generated by looking at the import statements in the tenant module’s source code. Tenant compilation schemas are always valid, self-contained GraphQL schemas.\n","categories":"","description":"What code does Viaduct generate for you?","excerpt":"What code does Viaduct generate for you?","ref":"/viaduct/docs/developers/generated_code/","tags":"","title":"Generated Code"},{"body":"Schema Change ManagementKey Principles for Schema Changes Backward Compatibility: Any schema change must ensure backward compatibility unless explicitly intended otherwise. Additive changes, such as adding new fields, are usually safe, while subtractive changes (like removing fields) often break client operations Hierarchy of Compatibility: Schema changes fall into multiple categories based on compatibility: Wire \u0026 Compilation Breaking Changes: These changes impact runtime behavior and client code compilation. For example, removing fields or changing field types can create runtime errors for existing clients Compilation-Only Breaking Changes: These affect code generation and compilation without impacting runtime compatibility. An example is adding a new enum value Schema Evolution: Schema changes are typically done within the constraints of the Directed Acyclic Graph (DAG) structure of schema modules. This ensures there are no circular dependencies between modules and maintains consistency during incremental updates Strict Validation: Automated validations, such as CI checks, detect incompatible schema changes during the pull request phase. These validations reference existing operations and client versions to assess impact. TODO how would an architect set up such a CI job? Schema Freeze and Deprecation: Fields being deprecated can be annotated with @deprecated tags and remain in the schema until older client versions are no longer in use. Examples of Practical Schema Updates: Extending Types: Adding new fields to an existing type via extend type. For example: extend type User { friends: [User] } Deprecations: Annotating fields slated for removal with @deprecated and updating client-side queries to avoid referencing these fields Modifications in Input Types: Converting an input type field from non-nullable (String!) to nullable (String) is considered safe ","categories":"","description":"Best practices for managing schema changes in Viaduct.","excerpt":"Best practices for managing schema changes in Viaduct.","ref":"/viaduct/docs/developers/schema_change_management/","tags":"","title":"Schema Change Management"},{"body":"","categories":"","description":"","excerpt":"","ref":"/viaduct/categories/","tags":"","title":"Categories"},{"body":"These docs cover how to use Viaduct, including tutorials, how-to guides, and reference materials.\nAPI Documentation Viaduct publishes two KDocs:\nTenant developers should refer to the Viaduct Tenant API documentation. Service architects and platform engineers should refer to the Viaduct Service API documentation. ","categories":"","description":"","excerpt":"These docs cover how to use Viaduct, including tutorials, how-to …","ref":"/viaduct/docs/","tags":"","title":"Documentation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/viaduct/tags/","tags":"","title":"Tags"},{"body":" Viaduct: A GraphQL Server Get Started A multitenant alternative to microservices\nViaduct is a GraphQL-based system that provides a unified interface for accessing and interacting with any data source.\nIt can be used by services as a way to access data efficiently and safely.\nViaduct provides you with one global schema and query system. Regardless of the engineering ownership or backing service, data access and mutations should follow a reliable and consistent pattern. The code which hydrates such queries should be maintained by the team which owns the data, to prevent the need to implement such logic by every team querying it.\nThe Viaduct engine is in production, at scale, at Airbnb where it has proven reliable. The developer API of Viaduct is under active development. In our roadmap we indicate which parts of the API are more or less subject to future change. This is a good time to join the project and influence the direction that this API takes!\nCore Values\nBe tenant-developer centric Seek to understand tenant engineers’ experiences, challenges and opportunities as a means to improve the frictions that exist today with the Viaduct framework.\nBe opinionated Approach solutions to problems with an opinionated view as a means to create clarity for tenant developers over excessive choice and unnecessary complexity.\nDeliver incrementally Start small and improve continuously through iteration on our technical solutions and processes. Ship incremental functionality on a frequent cadence as a means to build on an idea vs be stunted by perfection and a “solving for everything” mentality.\nScale for the future Build a system that can grow in reach and capability to more tenant engineers.\nWe envision Viaduct as the next-generation application runtime for product engineering teams. To achieve this, we focus on our core mission to empower product developers by delivering a seamless and efficient developer experience. We strive to maximize productivity and spark creativity through simplified APIs, improved performance, and the cultivation of team autonomy.\nCreated with ❤️ by ","categories":"","description":"","excerpt":" Viaduct: A GraphQL Server Get Started A multitenant alternative to …","ref":"/viaduct/","tags":"","title":"Viaduct"}]