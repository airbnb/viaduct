[{"body":"Getting Started with ViaductUsing a set of scripts bundled with the Viaduct release, this document will walk you through the process of setting up and modifying a very simple Viaduct application. Viaduct comes with built-in, Gradle-based tooling for building, testing, and running your sample application. This guide uses that tooling and assumes a basic familiarity with Gradle.\nSystem RequirementsGradle 8+ and Java 21.\nInstalling ViaductClone the Viaduct repository from GitHub and use Gradle to build and publish Viaduct’s artifacts.\ngit@github.com:airbnb/viaduct.git cd viaduct ./gradlew cleanBuildAndPublish This will build Viaduct’s artifacts and install them into your local Maven repository.\nAssuming you’re still in the viaduct directory, it will be convenient to\nexport VIADUCT=\"$(pwd)\" Bootstrapping an ApplicationViaduct comes with built-in Gradle tooling for building, testing, and publishing applications. This tooling includes a “bootstrap” script that configures a working “Hello, World!” application.\nThe first step is to create a basically blank, but functional, gradle project. To do this, in an empty directory (which we’ll henceforth refer to as your “root directory”), type the following:\n$VIADUCT/bootstrap-viaduct.sh This should turn your empty directory into a Viaduct “Hello, World!” application. That script will also run a test query against it. You can run a query yourself by typing:\n./gradlew -q run --args=\"'{ author }'\" Touring the ApplicationThe bootstrap script created a Viaduct application project for you with the following shape:\nyourroot/ build.gradle.gts src/ ... modules/ helloworld/ build.gradle.kts src/ ... (NOTE TO REVIEWERS: you’ll also see a directory called schema: as suggested below, this will be moved to .viaduct/schema to hide it. Also what’s called modules above is currently named tenants and uses the viaduct-tenant plugin rather than the viaduct-module one.)\nYou can see that a viaduct application is a multi-project Gradle project:\nThe root directory of the application uses the viaduct-app Gradle plugin, telling gradle this directory contains a Viaduct application. Note that the Gradle project in this directory does not need to be a Gradle root project: Viaduct apps can be embedded in larger code repositories.\nThe root project of our sample application has its own src directory: this directory contains the top-level “containing” application that sets up and runs the Viaduct application. Right now, this application is a command-line application that runs queries passed to it as a CLI argument. Later in this tutorial we will turn this into an actual web server.\nNote that the containing application code does not need to be inside the yourroot directory: it can be in a sibling directory, for example, or someplace else altogether. We’ll discuss this further below.\nThe modules directory contains the Viaduct modules containing the schema and business logic of your application. Each of these modules needs to use the viaduct-module plugin. Each of these modules should have a directory src/resources/schema containing .graphqls files with the schema being defined by that module. (This schema directory is searched recursively for such schema-containing files.)\nThe modules directory can contain multiple Viaduct modules organized in an arbitrary directory structure. At Airbnb, for example, this directory contains subdirectories named entity, data, and presentation, each representing a “layer” in our schema. The GraphQL modules are put under these directories. The modules directory can also contain “regular” Gradle projects, e.g., a modules/common project containing a library of common code shared by all modules.\nA viaduct-module project may not contain other viaduct-module projects. Also, viaduct-module projects cannot take Gradle dependencies on other viaduct-module projects: shared code must be put in a shared library, and the business logic of viaduct-modules should only interact using Viaduct GraphQL-based mechanisms.\nAt startup, the viaduct-app plugin will search for viaduct-module projects in the modules directory and automatically add them to the application-level project. So to add a new module, you simply need to create a viaduct-module project for it someplace under modules.\n(You might notice the directory .viaduct/schema in your application directory. This is a Gradle project managed entirely by Viaduct: it’s used at build time to collect up the schema definitions across all Viaduct modules and aggregating them into a single, consolidated schema. If you handcraft or write your own scripts to create Viaduct applications, this project must exist for the viaduct-app and viaduct-schema plugins to work correctly.\nExtending the ApplicationExtending the SchemaLet’s explore our sample application more deeply by extending its functionality. Viaduct is a “schema first” GraphQL environment, meaning you write your schema first, and then generate classes to write your code against. So in that spirit, let’s start by extending the schema, which as noted above you’ll find in src/main/resources/schema/schema.graphqls (paths in this section are relative to modules/helloworld/). You should see the following in that file:\nextend type Query @scope(to: [\"publicScope\"]) { greeting: String @resolver author: String @resolver } Viaduct itself has built-in definitions for the root GraphQL types Query and Mutation, although Viaduct doesn’t yet support subscriptions. (As explained in our SRE guide, the Mutation type can be removed, and the names of both root types can be configured.) Since Query is built-in, application code needs to extend it as illustrated above. You’ll also see in this schema fragment that both fields have @resolver applied to them, meaning that a developer-provided function is needed to compute their respective value. (All fields of Query must have @resolver applied to them.)\nLet’s extend this schema to add a new field, attributedGreeting, which will attribute the greeting to its author:\nextend type Query @scope(to: [\"publicScope\"]) { greeting: String @resolver author: String @resolver attributedGreeting: AttributedGreeting @resolver } type AttributedGreeting { greeting: String } There’s no practical reason to have the AttributedGreeting type here: attributedGreeting could’ve just been a String. We’re using a GraphQL object-type here in order to demonstrate some features of our API.\nExtending the codeThe resolvers for our sample app have been put in src/main/kotlin/com/example/viadapp/helloworld/HelloWorldResolvers.kt. We won’t copy its current content, but to support our new field apply the following changes to that file:\npackage com.example.viadapp.helloworld import viaduct.api.Resolver import com.example.viadapp.helloworld.resolverbases.QueryResolvers import viaduct.api.grts.AttributedGreeting // New import // New code: @Resolver(\"\"\" greeting author \"\"\") class AttributedGreetingResolver : QueryResolvers.AttributedGreeting() { override suspend fun resolve(ctx: Context): AttributedGreeting { val greeting = ctx.objectValue.getGreeting() val author = ctx.objectValue.getAuthor() return AttributedGreeting.Builder(ctx) .greeting(\"$author says: \\\"$greeting\\\"\") .build() } } As you make these changes you’ll notice two similar classes already in HelloWorldResolvers.kt, GreetingResolver which contains the resolver for the greeting field and AuthorResolver for the author field.\nWe’ll dive into this file in some detail, but let’s summarize what our new resolver does. The basic idea is that the resolver for attributedGreeting will combine the author and greeting fields into a string that attributes the greeting to the author. The resolver has access to these two fields because its @Resolver annotation indicates that it needs those fields: if the @Resolver annotation didn’t mention the author field, for example, then the attempt to read objectValue.author() would fail at runtime.\nLet’s examine some of the details of Viaduct that are illustrated by this file:\nTo support code-generation, Viaduct requires that the code that makes up an application be placed in packages whose fully-qualified names (FQNs) share a common prefix, called the application package prefix, or app prefix for short. This prefix can be anything; in our example, this prefix is com.example.viadapp. This prefix is declared in the build.gradle.kts file of the viaduct-app project.\nEach module has a fully-qualified module name based on its path in the modules directory. In the case of our hello-world module, since its Gradle project is found in modules/helloworld, its module name is helloworld. If our application had a module in modules/entity/users, that module’s name would be entity.users. The code that makes up a module should be placed in packages whose FQNs start with the concatenation of the app prefix and the module name, which is com.example.viadapp.helloworld in our example. We call this the module package prefix, or module prefix for short.\nViaduct generates code into two packages: viaduct.api.grts and \u003cmoduleprefix\u003e.resolverbases:\nThe acronym GRT stands for GraphQL Representational Type. These are generated Kotlin classes intended to represent GraphQL values. In our code fragment above, we import the GRT for the AttributedGreeting class because our resolver for attributedGreeting will need to return an instance of one.\nResolver classes are classes that contain the application logic that should be executed to resolve the value of a field. Each time a field is to be resolved, an instance of its resolver class is created (using an arbitrary dependency-injection framework if desired), and the resolver function in that class is then called.\nResolver classes are implemented by subclassing a generated resolver base class, which are found in the resolverbases subpackage. For each type T that has one or more @resolver fields, a static Kotlin object named TResolvers is created. For each field T.f that has a resolver, we generate a resolver base class named TResolvers.F (where the first letter of f is capitalized). To write a resolver for T.f, you subclass TResolvers.F and override the resolve function. (This subclassing approach is friendly to IDE autocomplete and genAI automation. Also, the type parameters on the Context argument are extensive, and this approach allows us to hide those from developers.)\nIn addition to subclassing the correct resolver base class, resolver classes must also be annotated with @Resolver, otherwise they won’t be recognized as resolver classes. (This supports testing and experimentation, where an “inactive” version of a resolver class with @Resolver can be written and tested before it replaces the current “live” version annotation.) As illustrated here, the @Resolver annotation can take what’s called a required selection set (RSS) which specifies what data the resolver wants to consume. The RSS is a GraphQL fragment on the containing-type of the field being resolved. In our example, since attributedGreeting is a field on Query, the RSS is a fragment on the Query type. As mentioned earlier, if a resolver attempts to access data it hasn’t requested in its RSS, an error is raised. Required selection sets are the only way the different modules of an application can interact with each other, creating strong encapsulation of the code inside a module.\nIn all resolvers, the ctx.objectValue property is how you access the values requested in your RSS. For a field on GraphQL type T, objectValue for the resolver for that field will be the GRT representing T (Query in our example). Note that the getters for the fields of objectValue are functions, not properties. It turns out these are suspending functions, which will wait for a value to be resolved by the responsible resolver before it returns. This asynchrony allows the engine to execute resolvers in parallel. (To prevent deadlocks, cycles between RSSs are checked-for at build time and also again at server startup time.)\n","categories":"","description":"Setting up and modifying a simple Viaduct application","excerpt":"Setting up and modifying a simple Viaduct application","ref":"/docs/getting_started/","tags":"","title":"Getting Started"},{"body":"SchemaNodes are types that are resolvable by ID and implement the Node interface. Every object type that implements the Node interface has a corresponding node resolver.\ninterface Node { id: ID! } type User implements Node { id: ID! firstName: String lastName: String displayName: String @resolver } Generated base classViaduct generates an abstract base class for all object types that implement Node. For the User example above, Viaduct generates the following code:\nobject NodeResolvers { abstract class User { open suspend fun resolve(ctx: Context): viaduct.api.grts.User = throw NotImplementedError() open suspend fun batchResolve(contexts: List\u003cContext\u003e): List\u003cFieldValue\u003cviaduct.api.grts.User\u003e\u003e = throw NotImplementedError() class Context: NodeExecutionContext\u003cviaduct.api.grts.User\u003e } // If there were more nodes, their base classes would be generated here } The nested Context class is described in more detail below.\nImplementationImplement a node resolver by subclassing the generated base class and overriding exactly one of either resolve or batchResolve.\nHere’s an example of a non-batching resolver for User that calls a user service to get data for a single user:\nclass UserNodeResolver @Inject constructor( val userService: UserServiceClient ): NodeResolvers.User() { override suspend fun resolve(ctx: Context): User { // Fetches data for a single User ID val data = userService.fetch(ctx.id.internalId) return User.builder(ctx) .firstName(data.firstName) .lastName(data.lastName) .build() } } Points illustrated by this example:\nDependency injection can be used to provide access to values beyond what’s in the execution context. You should not provide values for fields outside the resolver’s responsibility set. In the example above, we do not set displayName when building the User GRT. Alternatively, if the user service provides a batch endpoint, you should implement a batch node resolver. Node resolvers typically implement batchResolve to avoid the N+1 problem. Learn more about batch resolution here.\nContextBoth resolve and batchResolve take Context objects as input. This class is an instance of NodeExecutionContext:\ninterface NodeExecutionContext\u003cT: NodeObject\u003e: ResolverExecutionContext { val id: GlobalID\u003cT\u003e fun selections(): SelectionSet\u003cT\u003e } For the example User type, the T type would be the User GRT.\nNodeExecutionContext includes the ID of the node to be resolved, and the selection set for the node being requested by the query. Most node resolvers are not “selective,” i.e., they ignore this selection set and thus don’t call this function. In this case, as discussed above, it’s important that the node resolver returns its entire responsibility set.\nAdvanced users: If the selections function is not called by an invocation of a resolver, then the engine will assume that invocation will return the full responsibility set of the resolver and may take actions based on that assumption. If a resolver is going to be selective, then it must call this function to get its selection set rather than obtain it through some other means.\nSince NodeExecutionContext implements ResolverExecutionContext, it also includes the utilities provided there, which allow you to:\nExecute subqueries Construct node references Construct GlobalIDs Responsibility setThe node resolver is responsible for resolving all fields, including nested fields, without its own resolver. These are typically core fields that are stored together and can be efficiently retrieved together.\nIn the example above, the node resolver for User is responsible for returning the firstName and lastName fields, but not the displayName field, which has its own resolver. Note that node resolvers are not responsible for the id field, since the ID is an input to the node resolver.\nNode resolvers are also responsible for determining whether the node exists. If a node resolver returns an error value, the entire node in the GraphQL response will be null, not just the fields in the node resolver’s responsibility set.\n","categories":"","description":"Writing resolvers for nodes in Viaduct","excerpt":"Writing resolvers for nodes in Viaduct","ref":"/docs/resolvers/node_resolvers/","tags":"","title":"Node Resolvers"},{"body":"Code StructurePackagesThere are three main packages in particular making up the Tenant API:\nviaduct.api: These are classes like FieldExecutionContext (see below) which are the foundation of our tenant-facing API.\nviaduct.api.grts: This is where we put generated code for classes used to represent GraphQL types, see description of GRTs below.\n\u003cmodule-prefix\u003e.resolverbases: This is where we put generated base classes to be inherited by resolver classes (more on these shortly).\n","categories":"","description":"Tenant API Code Structure","excerpt":"Tenant API Code Structure","ref":"/docs/generated_code/code_structure/","tags":"","title":"Code Structure"},{"body":"TODO\n","categories":"","description":"Monitoring and returning errors in Viaduct.","excerpt":"Monitoring and returning errors in Viaduct.","ref":"/docs/observability/error_handling/","tags":"","title":"Error Handling"},{"body":"SchemaAll schema fields with the @resolver directive have a corresponding field resolver. This directive can only be placed on object, not interface fields.\nIn this example schema, we’ve added @resolver to the displayName field:\ntype User implements Node { id: ID! firstName: String lastName: String displayName: String @resolver } When to use @resolverField resolvers are typically used in the following scenarios:\nFields with arguments should have their own resolver, since resolvers don’t have access to the arguments of nested fields:\naddress(format: AddressFormat): Address @resolver Fields that are backed by a different data source than the core fields on a type should have their own resolver. In the example below, suppose the resolver for wishlists is backed by a Wishlist service endpoint, whereas firstName and lastName are backed by a User service endpoint:\nfirstName: String lastName: String wishlists: [Wishlist] @resolver This avoids executing the wishlists resolver and calling the Wishlist service if the field isn’t in the client query.\nFields that are derived from other fields, such as the displayName example shown in more detail below, which is derived from firstName and lastName. Although this example is simple, in practice there can be complex resolvers that have large required selection sets. This keeps the logic for these fields contained in their own resolvers which is easier to understand and maintain.\nGenerated base classViaduct generates an abstract base class for all schema fields with the @resolver directive. For User.displayName, Viaduct generates the following code:\nobject UserResolvers { abstract class DisplayName { open suspend fun resolve(ctx: Context): String? = throw NotImplementedError() open suspend fun batchResolve(contexts: List\u003cContext\u003e): List\u003cFieldValue\u003cString?\u003e\u003e = throw NotImplementedError() class Context: FieldExecutionContext\u003cUser, Query, NoArguments, NotComposite\u003e } // If there were more User fields with @resolver, their base classes would be generated here } The nested Context class is described in more detail below.\nImplementationImplement a field resolver by subclassing the generated base class, and overriding exactly one of either resolve or batchResolve. Learn more about batch resolution here.\nLet’s look at the resolver for User.displayName:\n@Resolver( \"fragment _ on User { firstName lastName }\" ) class UserDisplayNameResolver : UserResolvers.DisplayName() { override suspend fun resolve(ctx: Context): String? { val fn = ctx.objectValue.getFirstName() val ln = ctx.objectValue.getLastName() return when { fn == null \u0026\u0026 ln == null -\u003e null fn == null -\u003e ln ln == null -\u003e fn else -\u003e \"$fn $ln\" } } } As this example illustrates, the @Resolver annotation can contain an optional fragment on the parent type of the field being resolved. We call this fragment the required selection set of the resolver. In this case, the required selection set asks for the firstName and lastName fields of User, which are combined to generate the user’s display name. If a resolver attempts to access a field that’s not in its required selection set, an UnsetSelectionException is thrown at runtime.\nThe @Resolver annotation can also be used to declare data dependencies on the root Query type. Learn more about the annotation here.\nImportant clarification: there are no requirements on the names of these resolver classes: We use UserDisplayNameResolver here as an example of a typical name, but that choice is not dictated by the framework.\nContextBoth resolve and batchResolve take Context objects as input. This class is an instance of FieldExecutionContext:\ninterface FieldExecutionContext\u003cT: Object, Q: Query, A: Arguments, O: CompositeOutput\u003e: ResolverExecutionContext { val objectValue: T val queryValue: Q val arguments: A fun selections(): SelectionSet\u003cO\u003e } objectValue gives access to the object that contains the field being resolved. Fields of that object can be accessed, but only if those fields are in the resolver’s required selection set. If the resolver tries to access a field not included within its required selection set, it results in an UnsetSelectionException at runtime.\nqueryValue is similar to objectValue, but applies to the root query object of the Viaduct central schema. Like objectValue, fields on queryValue can only be accessed if they are in the resolver’s required selection set.\narguments gives access to the arguments to the resolver. When a field takes arguments, the Viaduct build system will generate a GRT representing the values of those arguments. If User.displayName took arguments, for example, Viaduct would generate a type User_DisplayName_Arguments having one property per argument taken by displayName. In our example, the field execution context for displayName is parameterized by the special type NoArguments indicating that the field takes no arguments.\nselections() returns the selections being requested for this field in the query, same as the selections function for the node resolver. The SelectionSet type is parameterized by the type of the selection set. For example, in the case of User’s node resolver, selections returned SelectionSet\u003cUser\u003e. In the case of displayName, selections returns SelectionSet\u003cNotComposite\u003e, where the special type NotComposite indicates that displayName does not return a composite type (it returns a scalar instead).\nSince NodeExecutionContext implements ResolverExecutionContext, it also includes the utilities provided there, which allow you to:\nExecute subqueries Construct node references Construct GlobalIDs Responsibility setFor scalar and enum fields like displayName, the field resolver is just responsible for resolving the single field. If the field has a node type, the field resolver constructs a node reference using just the node’s GlobalID, which tells the engine to run the node resolver. For fields with non-node object types, the field resolver is responsible for all nested fields without its own resolver.\n","categories":"","description":"Writing resolvers for fields in Viaduct","excerpt":"Writing resolvers for fields in Viaduct","ref":"/docs/resolvers/field_resolvers/","tags":"","title":"Field Resolvers"},{"body":"TODO document data fetcher exception handler\n","categories":"","description":"Instrumenting data fetcher exceptions.","excerpt":"Instrumenting data fetcher exceptions.","ref":"/docs/observability/instrumentation/","tags":"","title":"Instrumentation"},{"body":"Both node resolvers and field resolvers can be implemented using the batchResolve function. This provides an alternative to the widely used data loader pattern.\nThe N+1 problemConsider this example schema:\ntype Query { recommendedListings: [Listing] @resolver } type Listing implements Node { id: ID! title: String } Suppose the query below returns 3 recommended listings. A Listing node resolver that makes a call to a listings service to fetch a single listing in the resolve function will result in 3 separate calls to the service.\nquery { recommendedListings { id title } } This is the N+1 problem, which is commonly solved by implementing a data loader that batches calls to the listings service. The resolver calls the data loader, which then calls the data source.\nbatchResolveIn Viaduct, you can implement the batchResolve function and directly call the data source instead of going through a data loader. Under the hood, Viaduct still uses a data loader to batch requests. However, this data loader is part of Viaduct’s framework, not something that application developers need to write and maintain. Here’s an example Listing batch node resolver:\n@Resolver class ListingNodeResolver @Inject constructor(val client: ListingClient) : NodeResolvers.Listing() { override suspend fun batchResolve(contexts: List\u003cContext\u003e): List\u003cFieldValue\u003cListing\u003e\u003e { val listingIDs = contexts.map { it.id.internalID } val responses = client.fetch(listingIDs) return contexts.map { ctx -\u003e val listingID = ctx.id.internalID val response = responses[listingID] FieldValue.ofValue( Listing.Builder(ctx) .title(response.title) .build() ) } } } InputbatchResolve takes a list of Context objects as input. This is the same Context object type passed to the non-batching resolve function. Viaduct’s GraphQL execution engine batches these contexts before passing them to the batchResolve function.\nOutputThe list that batchResolve returns must have the same number of elements as the input list. Each output value corresponds to the input Context at the same list index.\nFieldValueNotice that the output list elements are wrapped in FieldValue (e.g., List\u003cFieldValue\u003cListing\u003e\u003e in the example above). This represents either a successfully resolved value or an error value.\nUsage:\nFieldValue.ofValue(v): constructs a successfully resolved value, as shown in the example above FieldValue.ofError(e): constructs an error value, where e is an exception. The corresponding value in the GraphQL response will be null, and there will be an error in the errors array. When to use batchResolveOverride batchResolve whenever you need to fetch data from an external data source that supports batch loading. This solves the N+1 problem and similar issues where multiple parts of a GraphQL query fetch data that can be batched together.\nIf your resolver does not have external data dependencies, there is generally no benefit to implementing batchResolve.\nThose familiar with data loaders may know that they also provide an intra-request cache. In Viaduct, this memoization cache is decoupled from batching, so you do not need to implement batchResolve for caching purposes.\n","categories":"","description":"Batch node and field resolvers","excerpt":"Batch node and field resolvers","ref":"/docs/resolvers/batch_resolution/","tags":"","title":"Batch Resolution"},{"body":"Field resolvers must be annotated with @Resolver to be registered. This annotation class also allows resolvers to declare data dependencies in the form of required selection sets via objectValueFragment and queryValueFragment:\nannotation class Resolver( @Language(\"GraphQL\") val objectValueFragment: String = \"\", @Language(\"GraphQL\") val queryValueFragment: String = \"\", val variables: Array\u003cVariable\u003e = [] ) objectValueFragment: a GraphQL fragment on the object type that contains the field being resolved. In the User.displayName example below, the fragment must be on the User type.\nqueryValueFragment: a GraphQL fragment on the root query type.\nvariables: values of variables used in objectValueFragment or queryValueFragment.\nRequired selection set syntaxA resolver can optionally specify one or both of objectValueFragment and queryValueFragment using either the shorthand fragment syntax, or full fragment syntax. Values can be accessed using Context.objectValue and Context.queryValue.\nShorthand syntaxThe shorthand fragment syntax just includes the selections within the fragment body.\nHere’s an example of what this looks like for a User.displayName field. The selections must be on the User type:\n@Resolver(\"firstName lastName\") class UserDisplayNameResolver : UserResolvers.DisplayName() The shorthand fragment syntax can also be used for queryValueFragment. The selections must be on the root query type:\n@Resolver(queryValueFragment = \"user { firstName lastName }\") Full fragment syntaxThe full fragment syntax is the regular GraphQL fragment syntax. You can name the fragment whatever you’d like, although we typically use _ for the fragment name when there’s only a single fragment to indicate that the name isn’t used anywhere:\n@Resolver(\"fragment _ on User { firstName lastName }\") You can define multiple named fragments and reference them within your main fragment:\n@Resolver( queryValueFragment = \"\"\" fragment _ on Query { listing { cover: coverImage { ...ImageDetails } rooms { images { ...ImageDetails } } } } fragment ImageDetails on Image { url caption } \"\"\" ) Note that if you have multiple fragments on the type of the main fragment (either the object type or the query type), the primary one needs to be named Main:\n@Resolver( \"\"\" fragment Main on User { firstName lastName ...UserProfilePhoto } fragment UserProfilePhoto on User { profilePhoto { url caption } } \"\"\" ) Accessing required selection set valuesYou can access the required selection set values via the Context object given as input to the field resolver. Context.objectValue and Context.queryValue are GRTs of the object and Query types, e.g.\nctx.objectValue.getFirstName() ctx.queryValue.getListing().getCoverImage(alias = \"cover\") If the resolver tries to access a field not included within its required selection set, it results in an UnsetSelectionException at runtime.\nIn the Kotlin API, each of the field getters are suspend functions. Your resolver may begin execution before the selections have been fully resolved via their corresponding resolvers. If that happens, the field getter will suspend until the field is resolved.\nVariablesThe fragments in @Resolver annotations can contain variables. These variables can be bound to values in one of two ways:\nVia the variables parameter in @Resolver Via the resolver’s variable provider @Resolver variables parameterVariables may be bound using the variables parameter of @Resolver, which is an array of @Variable annotations. For example, consider this resolver configuration for the field MyType.foo that takes an argument include:\n@Resolver( objectValueFragment = \"\"\" fragment _ on MyType { field @include(if: ${'$'}shouldInclude) } \"\"\", variables = [Variable(\"shouldInclude\", fromArgument = \"includeMe\")] ) This resolver fragment uses a shouldInclude variable. At runtime, the value for this variable will be determined by the value of the includeMe argument to MyType.foo. To support nested GraphQL input types, the fromArgument string can contain a dot-separated path.\nThere are three mutually-exclusive parameters to the @Variable class that can be used to set the value of a variable:\nthe fromArgument parameter just illustrated the fromObjectField parameter, which takes a dot-separated path relative to the objectValue of an execution. If used, the path must be a selection defined in the resolver’s objectValueFragment. the fromQueryField parameter. This parameter is analogous to fromObjectField, but the path describes a selection in the resolver’s queryValueFragment. VariablesProviderThe variables parameter does not allow arbitrarily-computed values to be used as variables. To support dynamic use cases, a VariablesProvider can be used.\nFor example, consider a resolver for MyType.foo whose required selection set uses variables named startDate and endDate. To provide dynamically-computed values for these variables, the implementation for MyTypeResolvers.Foo may nest a class that implements the VariablesProvider interface:\n@Variables(types = \"startDate: Date, endDate: Date\") class Vars : VariablesProvider\u003cMyType_Foo_Arguments\u003e { override suspend fun provide(args: MyType_Foo_Arguments) = LocalDate.now().let { mapOf( \"startDate\" to it, \"endDate\" to it.plusDays(7) ) } } } The value of the types parameter to @Variables must conform to VariableDefinitionlist from GraphQL Spec. The args parameter to the provide function is the arguments of the field whose resolver class defines this variable provider, or NoArguments if the field takes no arguments.\n","categories":"","description":"Using the @Resolver annotation","excerpt":"Using the @Resolver annotation","ref":"/docs/resolvers/resolver_annotation/","tags":"","title":"Resolver Annotation"},{"body":"GraphQL resolvers frequently need to link to other Node types in the graph. Consider this example, where a Listing type has an edge to its host user:\ntype Listing implements Node { id: ID! host: User ... } type User implements Node { id: ID! ... } Rather than requiring the Listing resolver to also be responsible for resolving User data, the Listing resolver can use Context.nodeFor() to create a node reference. The nodeFor function takes a GlobalID as input and returns a special GRT for that node:\n@Resolver class ListingNodeResolver @Inject constructor(val client: ListingClient) : NodeResolvers.Listing() { override suspend fun resolve(ctx: Context): Listing { val data = client.fetch(ctx.id.internalID) val hostGlobalID = ctx.globalIDFor(User.Reflection, data.hostID) // Creates a node reference as a User GRT val host = ctx.nodeFor(hostGlobalID) return Listing.builder(ctx) .host(host) /* ... other fields populated from [data] */ .build() } } When this resolver returns, the Viaduct engine will invoke the User node resolver, as well as any field resolvers on the User type, to fetch data for the Listing.host field.\nThis example illustrates a subtle aspect of the “responsibility set” of resolvers, which is that the responsibility for resolving a field with a node type is split between the resolver whose responsibility set contains the field, and the resolver of the node being returned. Specifically, the containing resolver is responsible for resolving the node’s id field and returning a node reference as illustrated here. From there, the node resolver takes over to resolve the rest of the node’s responsibility set.\nWe noted above that the GRT returned by nodeFor is “special.” It’s special because, in the code that calls nodeFor, only the id field is set; all other fields are not set and will throw an exception on an attempt to read them. If for some reason a resolver needs a resolved node rather than a node reference, the resolver can use a subquery.\n","categories":"","description":"Creating node references in resolvers","excerpt":"Creating node references in resolvers","ref":"/docs/resolvers/node_references/","tags":"","title":"Node References"},{"body":"TutorialsThese step-by-step guides will teach you how to build powerful GraphQL APIs with minimal code.\nHow It Works: Write GraphQL schema with @resolver directives\nBuild your project - Viaduct generates resolver base classes\nImplement resolvers - Extend generated classes with your logic\nGet a working API - Type-safe, performant GraphQL server\nTutorial PathFollow these tutorials in order to master Viaduct’s resolver patterns:\n1. Field Resolver TutorialStart here! Learn the most basic resolver type.\nWhat you’ll learn: How to create computed fields with custom logic\nKey concepts: Field resolvers, Query type resolvers, @Resolver annotation\nExample: A simple foo: String! field that returns computed values\nGenerated classes: QueryResolvers.*\n2. Node Resolver TutorialLearn the foundation of Viaduct’s object system.\nWhat you’ll learn: How to create objects that can be refetched by ID\nKey concepts: Node interface, GlobalID system, Node resolvers\nExample: A Foo type that implements Node and can be resolved by ID\nGenerated classes: NodeResolvers.*, Global ID encoding/decoding\nWhy it matters: Foundation for all object resolution in Viaduct\n3. Simple Resolvers TutorialSee how Field and Node resolvers work together.\nWhat you’ll learn: How different resolver types interact\nKey concepts: objectValueFragment, accessing parent data, resolver composition\nExample: A User with computed fullName field using firstname + lastname\nGenerated classes: QueryResolvers.*, UserResolvers.*, NodeResolvers.*\nAdvanced feature: Field resolvers accessing parent object data\nKey Concepts Across All TutorialsThe @resolver Directivedirective @resolver on FIELD_DEFINITION | OBJECT This tells Viaduct “generate a resolver for this”. Different placements create different resolver types:\nOn object types: type User @resolver → Creates NodeResolvers.User() (Node Resolver)\nOn Query fields: foo: String! @resolver → Creates QueryResolvers.Foo()\nOn object fields: fullName: String! @resolver → Creates UserResolvers.FullName()\nResolver Types Resolver Type Purpose Generated Class When to Use Node Resolver Create/fetch objects by GlobalID NodeResolvers.TypeName() Objects that implement Node interface Query Field Resolver Handle root query fields QueryResolvers.FieldName() Top-level API entry points Object Field Resolver Compute derived fields TypeResolvers.FieldName() Fields that need parent data or computation The GlobalID SystemViaduct’s built-in global object identification:\nEncodes: Object type + internal ID into a single string\nType-safe: Can’t accidentally use wrong ID for wrong type\nUtilities: ctx.globalIDFor() to create, ctx.nodeFor() to resolve\nStandard: Follows Relay specification for global object identification\nField Resolver Data AccessField resolvers can access parent object data:\n@Resolver(objectValueFragment = \"fragment _ on User { firstname lastname }\") Tells Viaduct exactly what parent data your resolver needs\nFramework automatically fetches required fields\nAvailable via type-safe ctx.objectValue.getFirstname()\n","categories":"","description":"Step-by-step guides to using Viaduct","excerpt":"Step-by-step guides to using Viaduct","ref":"/docs/tutorials/","tags":"","title":"Tutorials"},{"body":"Context.query can be used to execute a subquery, i.e., a GraphQL query operation rooted in the full-schema’s Query root type. As an example, we can modify the resolver for User.displayName to incorporate data that it loads from Query:\n@Resolver( \"fragment _ on User { id firstName lastName }\" ) class UserDisplayNameResolver: UserResolvers.DisplayName() { override suspend fun resolve(ctx: Context): String? { val id = ctx.objectValue.getId() val fn = ctx.objectValue.getFirstName() val ln = ctx.objectValue.getLastName() // determine if user is the logged-in user, in which case // we add a suffix to their displayName // first, construct a selection set on the Query object val querySelections = ctx.selectionsFor( Query.Reflection, \"{ viewer { user { id } } }\" ) // second, load the selections on Query val query = ctx.query(querySelections) val isViewer = id == query.getViewer()?.getUser()?.getId() val suffix = if (isViewer) \" (you!)\" else \"\" return when { fn == null \u0026\u0026 ln == null -\u003e null fn == null -\u003e ln ln == null -\u003e fn else -\u003e \"$fn $ln$suffix\" } } } We call this process of loading a selection set an “imperative subquery”, which is distinguished from the more “declarative” method of data loading used by the @Resolver annotation. It can be used to load selections on the root Query object that are not known until runtime.\n","categories":"","description":"Executing subqueries in resolvers","excerpt":"Executing subqueries in resolvers","ref":"/docs/resolvers/subqueries/","tags":"","title":"Subqueries"},{"body":"Mutation fields should use the @resolver directive to provide a field resolver that executes the mutation. For the following example schema:\nextend type Mutation { publishListing(id: ID! @idOf(type: \"Listing\")): Listing @resolver } The resolver might look like:\n@Resolver class PublishListingResolver @Inject constructor( val client: ListingServiceClient ) : MutationResolvers.PublishListing() { override suspend fun resolve(ctx: Context): Listing { client.publish(ctx.arguments.id.internalID) return ctx.nodeFor(ctx.arguments.id) // Creates a Listing node reference } } As this example shows, resolvers for mutation fields are almost identical to query field resolvers. A major difference is that Context implements MutationFieldExecutionContext. This allows mutation field resolvers to execute submutations using Context.mutation() in addition to executing subqueries using Context.query().\nMutation field resolvers should still be annotated with @Resolver. However, they may not provide a required selection set using objectValueFragment, since those selections would include other mutation fields. Mutation field resolvers can execute other mutation fields by calling Context.mutation() instead.\n","categories":"","description":"Mutating data in Viaduct","excerpt":"Mutating data in Viaduct","ref":"/docs/resolvers/mutations/","tags":"","title":"Mutations"},{"body":"In Viaduct, all module code is provided in the form of either a node resolver or a field resolver. Node and field resolvers are implemented similarly:\nSchema: The schema is the source of truth for what resolvers should exist. Define node types and add the @resolver directive to fields you want to provide resolvers for. Generated base classes: Viaduct generates abstract classes for all node and field resolvers based on the schema. Implementation: Implement a resolver by providing a subclass of the generated base class and overriding either resolve or batchResolve. Responsibility setsResponsibility sets (also known as “responsibility selection sets”) are an important concept in the Viaduct API. Every node and field resolver is responsible for resolving the fields in its responsibility set. This includes all fields, including nested fields, that themselves do not have a resolver. The node and field resolver pages provide more details with examples.\nInjectionViaduct is designed to create instances of resolver classes through dependency injection. You can define this behavior by implementing this interface:\ninterface TenantCodeInjector { fun \u003cT\u003e getProvider(clazz: Class\u003cT\u003e): Provider\u003cT\u003e } Examples of using this dependency injection mechanism are available in the demo applications.\nIf you do not provide an implementation of TenantCodeInjector, Viaduct will use a naive default implementation that assumes a zero-argument constructor is available for all resolvers. Whenever the GraphQL execution engine needs to invoke a resolver, it will use this to construct an instance of the resolver. While sufficient for toy applications, we strongly suggest using a dependency injection framework for real applications.\n","categories":"","description":"Understanding resolvers in Viaduct","excerpt":"Understanding resolvers in Viaduct","ref":"/docs/resolvers/","tags":"","title":"Resolvers"},{"body":"MetricsViaduct provides built-in metrics on fields, field resolvers, node resolvers and access checkers (“measured entities”). These metrics are focused on latency, error rates and attribution. Viaduct offers observability to support the following use cases:\nLatency Determine latency (across various percentiles) in aggregate for measured entities Figure out the sequence of executions of measured entities happening in a given request that is contributing to latency (critical path) Understand why each measured entity is getting called / executed Attribute each measured entity running in a request to a specific tenant Error Rate Monitor fail states of operations (either partial or full failure) on Viaduct What is the error rate for a given operation? If the error rate is greater than zero, what ‘measured entities’ are causing the error? What is the cause? Understand what is causing each operation failure Errors are attributable to the responsible ‘measured entity’(field or resolver) that triggered the exception Errors in resolvers should propagated to the field that resulted in the resolver being called Be able to find exception stack trace (when applicable) Monitor operation for error rate Errors are eventually propagated to the top level operation to signify if the operation failed or not AttributionDue to the async nature of Viaduct’s execution strategy and use of caching, this requires special callout. Viaduct’s observability supports the following use cases:\nDevelopers are able to understand why their field is slow and to attribute the slowness to a specific measure entity. For example, the writer of a DerivedFieldProvider wants to understand why their field is slow. Developers are able to understand why an error is thrown and attribute the error to a specific code component. Similarly as the above example, we need a way to help DFP B understand how field A errors are impacting its execution. Developers are also able to understand what code component triggered the fetch for their field, and what the frequency is for the fetch. If taking the above example, field A should be able to know DFP B triggers its fetch and the frequency of the fetch. Available Metrics viaduct.execution Full execution lifecycle metric which measures end-to-end execution time for the entire GraphQL request Measurements: Latency (p50, p75, p90, p95) and count Tags: operation_name: GraphQL operation name (if available) success: true if no throwable and data is present, false otherwise viaduct.operation Operation-level metric which measures the time to execute the specific GraphQL operation Measurements: Latency (p50, p75, p90, p95) and count Tags: operation_name: GraphQL operation definition name (if available) viaduct.field Field-level metric which measures the time to fetch/resolve individual GraphQL fields Measurements: Latency (p50, p75, p90, p95) and count Tags: operation_name: GraphQL operation name (if available) field: Field path in format ParentType.fieldName or just fieldName for root fields success: true if no exception thrown during field fetch, false otherwise ","categories":"","description":"Monitoring and Logging in Viaduct","excerpt":"Monitoring and Logging in Viaduct","ref":"/docs/observability/","tags":"","title":"Observability"},{"body":"Unit Testing resolversResolver unit tests can extend ViaductResolverTestBase, which provides utilities for mocking ExecutionContext and handles injection. In order to test a resolver, inject it into the test class, and then call its resolve function in your test case with a ExecutionContext constructed using ViaductResolverTestBase.contextForResolver(...).\n","categories":"","description":"Testing Tenant Code","excerpt":"Testing Tenant Code","ref":"/docs/testing/","tags":"","title":"Testing"},{"body":"Viaduct uses two different Kotlin types to represent GraphQL ID types: GlobalID\u003cT\u003e and String. GlobalID is an object that consists of a type and an internal ID. They are used to uniquely identify node objects in the graph. GlobalID values support structural equality, as opposed to referential equality.\nThere are two conditions under which GlobalID\u003cT\u003e will be used:\nThe id field of a Node object type A field of type ID with the @idOf(type:\"T\") directive, where T must be a GraphQL object or interface type that implements Node Elsewhere in the Kotlin code, String will be used for IDs.\nFor the examples below, id, id3 and f2 are GlobalIDs and while id2 and f1 are Strings.\ntype MyNode implements Node { id: ID! id2: ID! id3: ID! @idOf(type: \"MyNode\") } input Input { f1: ID! f2: ID! @idOf(type: \"MyNode\") } If a Node object type implements an interface, and that interface has an id field, then that interface must also implement Node.\nInstances of GlobalID can be created using the Context objects provided to resolvers, e.g., ctx.globalIDFor(User.Reflection, \"123\").\n","categories":"","description":"Global identifiers for nodes","excerpt":"Global identifiers for nodes","ref":"/docs/globalids/","tags":"","title":"GlobalIDs"},{"body":"ScopesThis document provides an overview on how to define scopes on the Viaduct GraphQL schema.\nThe scoop on scopesIn order to make schema visibility control more explicit and intuitive, we introduced Scopes.\nScopes are a mechanism for encapsulating parts of your schema for information-hiding purposes. Two commonly-used scopes are viaduct, which has a bigger schema available to all of your internal systems, and viaduct:public, a smaller schema available publicly to your frontend clients. Almost all data types will have viaduct scope, which allows them to be queried by backend clients. Some data types, or a subset of fields within data types that can be queried by frontend clients, also have the viaduct:public scope.\nScopes leverage GraphQL type extensions to separate fields within a type that belong to different scopes. This convention avoids the need for annotating each field in the schema with @scope directives, and provides a way to separate different types of fields in the SDL to optimize for human readability.\nFor example, if we are to expose only field1 from Foo to viaduct:public but not field2 or field3, we will organize our schema like this:\ntype Foo @scope(to: [\"viaduct\", \"viaduct:public\"]) { field1: Bar } extend type Foo @scope(to: [\"viaduct\"]) { field2: Int field3: String } type Bar @scope(to: [\"viaduct\", \"viaduct:public\"]) { field4: Boolean field5: String } As you will also learn from the later sections, the scope validation system will also enforce explicitness so that each type (including object, input, interface, union, and enum) and their extensions will always have at least one scope value.\n[alert]\nEither nothing is scoped or everything has a scope applied to it. There is no default scope.\n[/alert]\nMultiple SchemasA single instance of the Viaduct framework can expose multiple schemas. Within Airbnb, for instance, the Viaduct service itself, exposes a different, more complete schema to internal clients than it exposes to external Web and mobile clients. Scopes also provide encapsulation that allows us to hide implementation details present in your central schema.\nEvery schema exported by an instance of the Viaduct framework is called a scope set. A scope set is identified by a schema ID. The particular scope set seen by a given request to the Viaduct framework is controlled by the schemaId field of viaduct.service.api.ExecutionInput. In the above example, viaduct and viaduct:public are both schema IDs. You can use as many schema IDs as you like with whatever naming scheme fits your use case.\nGuidelines for annotating types with @scopeAlways append @scope to the main typeWhenever you are creating a new type (including object type, input type, interface, union, and enum), always append @scope(to: [\"scope1\", \"scope2\", ...]) to the type itself. (Replace \"scope1\", \"scope2\", etc. with your desired scopes)\nAll the attributes within the main type will share and be exposed to ALL the scopes defined in the @scope values.\n# field1 and field2 will be visible to both Viaduct data API and public API type Foo @scope(to: [\"viaduct\", \"viaduct:public\"]) { field1: Int field2: String } # CONSTANT1 and CONSTANT2 will be visible to Viaduct data API, as well as both foo and bar. enum Bar @scope(to: [\"viaduct\", \"foo\", \"bar\"]) { CONSTANT1 CONSTANT2 } # field from Baz is only visible to Viaduct data API input Baz @scope(to: [\"viaduct\"]) { field: Boolean } Create type extensions and move fields with narrower scopes to this extensionIf you need to limit the visible scopes for certain fields, create a type extension, move those fields over, and append @scope with proper scopes.\nFor example, the following definition will expose field3 to private only.\ntype Foo @scope(to: [\"public\", \"private\"]) { field1: Int field2: String } extend type Foo @scope(to: [\"private\"]) { field3: Boolean } ValidationIn GraphQL SDL, scopes are referenced by their string value, and in Kotlin are referenced by the strongly typed enum member. The SDL will be validated at build time to ensure invalid scope names were not referenced.\nIn addition to detecting invalid scope names, the Viaduct Bazel validators will perform other static analysis on the schema in order to detect invalid or confusing scope usage.\nDetecting inaccessible fields when referencing another typeStatic analysis tooling will detect @scope usages that cause inaccessible fields. Take the following schema excerpt:\ntype User @scope(to: [\"scope1\",\"scope2\"]) { id: ID! firstName: String lastName: String } type Listing @scope(to: [\"scope3\"]) { user: User # this field would never be accessible } In the above example, the User type is only available in the scope1 and scope2 scopes, and the Listing type is only available in the scope3 scope. The user field in Listing is of type User, but User is not visible to the scopes associated with the Listing type. Thus, filtering the schema to any of the three scopes used in this schema excerpt would result in the user field within Listing being filtered out of the schema.\nThis invariant can be corrected in two ways:\nThe Listing type’s scope should be modified to include scope1 or scope2, OR The User type’s scope should be modified to include the scope3 scope. Auto prune a type when all of its fields are out of scopeWhen all the fields of a type are out of scope, this type will not be accessible, even if it is within the scope. Therefore, Viaduct prunes such empty types recursively in the generated schema. For example:\ntype StaySpace @scope(to: [\"viaduct\", \"listing-block\", \"viaduct:private\"]) { spaceId: Long metadata: SpaceMetadata } type SpaceMetadata @scope(to: [\"viaduct\", \"listing-block\"]) { bathroom: StayBathroomMetadata bedroom: StayBedroomMetadata } type StayBathroomMetadata @scope(to: [\"viaduct\", \"viaduct:private\"]) { spaceName: String } type StayBedroomMetadata @scope(to: [\"viaduct\", \"viaduct:private\"]) { spaceName: String } Filtering the above schema excerpt to listing-block will make SpaceMetadata an empty type, since both StayBathroomMetadata and StayBedroomMetadata will not be in the scope. Thus, SpaceMetadata attribute will be pruned from StaySpace in the listing-block scope, as it will not be reachable, despite that this type has annotated with listing-block scope.\nDetect invalid scope usage within a typeWhen leveraging a type extension to define fields that are available in a specific scope, it’s essential that the scope specified in the directive on the type extension be one of the scopes specified in the original definition of the type.\nTake for example the following schema excerpt:\ntype User @scope(to: [\"viaduct\",\"user-block\"]) { id: ID! firstName: String lastName: String } extend type User @scope(to: [\"viaduct:internal-tools\"]) { aSpecialInternalField: String } This example shows an incorrect usage of the scope directive on the type extension, as the viaduct:internal-tools scope is not specified as a scope on the original User type definition.\nThe correct version of the above example would be:\ntype User @scope(to: [\"viaduct\",\"viaduct:internal-tools\", \"user-block\"]) { id: ID! firstName: String lastName: String } extend type User @scope(to: [\"viaduct:internal-tools\"]) { aSpecialInternalField: String } This validation rule enforces the convention that common fields be defined in the original type definition, and fields that are defined in specific scopes be specified using type extensions.\nTroubleshootingIf you get an error like Unable to find concrete type ... for interface ... in the type map or Unable to find concrete type ... for union ... in the type map, it’s because the interface or union type is defined in schema module A, and the concrete type that implements the interface or extends the union is defined in schema module B, and B does not depend on A.\nFor example, this is not allowed because UnionA is defined in the data module and its member TypeA is defined in the entity module. The entity module does not depend on the data module.\n# modules/entity type TypeA { fieldA: String } # modules/data type TypeB { fieldB: String } union UnionA = TypeB extend UnionA = TypeA # \u003c-- not ok To fix it, make sure you define the concrete type of interface or union in a schema module that is dependent on the schema module where the interface or union type is defined.\nFor example, you can “lift” up the type definition for UnionA to the entity module:\n# modules/entity type TypeA { fieldA: String } union UnionA = TypeA # modules/data type TypeB { fieldB: String } extend type UnionA = TypeB # \u003c-- ok ","categories":"","description":"Schema visibility and access control in Viaduct.","excerpt":"Schema visibility and access control in Viaduct.","ref":"/docs/scopes/","tags":"","title":"Scopes"},{"body":"GraphQL Representational Type (GRT)The API generates two kinds of classes: GraphQL Representational Types (GRTs), and resolver base classes, described in the Resolvers section.\nFor each GraphQL type, Viaduct generates a number of Kotlin classes to represent its values. These classes are found in the viaduct.api.grts package. We generate two classes for each GraphQL type: a class representing a value of a given type, and a builder-class allowing you to construct a value of a given type. Consider this simple schema:\ntype User implements Node { id: ID! firstName: String lastName: String displayName: String } The signature of the GRT for this type would look approximately like this:\npackage viaduct.api.grts class User private constructor(...): NodeObject { suspend fun getId(alias: String? = null): GlobalID\u003cUser\u003e suspend fun getFirstName(alias: String? = null): String? suspend fun getLastName(alias: String? = null): String? suspend fun getDisplayName(alias: String? = null): String? class Builder(ctx: ExecutionContext): DynamicValueOutputBuilder\u003cUser\u003e { fun id(id: GlobalID\u003cUser\u003e): Builder fun firstName(firstName: String?): Builder fun lastName(lastName: String?): Builder fun displayName(displayName: String?): Builder override fun build(): User } } NodeObject is a tagging interface (i.e., an interface with no methods) for GRTs representing GraphQL object types. DynamicValueOutputBuilder\u003cT\u003e is an interface for builders of such types (it defines a build function that returns a T).\nThe values from a fragment on User (for example) are accessed through the GRT for User. As a result, the Viaduct GRTs for object types distinguish fields that are “not set,” because they haven’t been requested for in the fragment, from fields that are in the fragment and thus are “set.” If you attempt to access a field that has not been set, a UnsetSelectionException exception will be thrown, even if that field is nullable. Also, when you build an object-type value, you do not have to set all fields, even if those fields are non-nullable.\nThe GRTs for interface types are Kotlin interfaces with suspending getters (but no builders), while the GRTs for union types are simply Kotlin “tagging” interfaces (i.e., Kotlin interfaces with no members).\nFor GraphQL input-object types, the pattern for GRTs is similar to that for output-object types illustrated by User. However, instead of suspending getter functions, the GRTs for input-object types use Kotlin properties for accessing fields. “Partial” input-object types are not possible: every field of an input-object GRT instance is defined (thus, FieldNotSet is never thrown when accessing their fields). To achieve this invariant, builders for input-object types are stricter than those for object types: if you call build on an InputType.Builder instance without having set all required fields of that type, then build will raise a runtime error. A field is “required” if it’s defined with the `!` (non-null) wrapper and it has no default value.\nViaduct is what is known as a “schema-first” GraphQL system: developers write GraphQL schema directly, and the Viaduct system generates “GraphQL representational types (GRTs)” to allow developers to read and write the types expressed by the schema.\nAny single tenant module consumes only a small fraction of the central schema, so building representational types for the entire schema for every tenant is wasteful. Instead, Viaduct uses “compilation schemas”, a per-tenant, private view of the central schema consisting of only the schema elements used by a tenant. This makes Viaduct builds fast and scalable by ensuring that tenants are built in parallel and are only rebuilt when needed.\nThe tenant compilation schema is used to generate the GRTs described above. The compilation schema is a subset of the total schema visible to a tenant, a subset generated by looking at the import statements in the tenant’s source code. Tenant compilation schemas are always valid, self-contained GraphQL schemas.\n","categories":"","description":"What code does Viaduct generate for you?","excerpt":"What code does Viaduct generate for you?","ref":"/docs/generated_code/","tags":"","title":"Generated Code"},{"body":" This is a placeholder page that shows you how to use this template site.\n","categories":"","description":"What does your user need to know to try your project?","excerpt":"What does your user need to know to try your project?","ref":"/docs/multiple_modules/","tags":"","title":"Multiple Modules"},{"body":"Schema Change ManagementKey Principles for Schema Changes Backward Compatibility: Any schema change must ensure backward compatibility unless explicitly intended otherwise. Additive changes, such as adding new fields, are usually safe, while subtractive changes (like removing fields) often break client operations Hierarchy of Compatibility: Schema changes fall into multiple categories based on compatibility: Wire \u0026 Compilation Breaking Changes: These changes impact runtime behavior and client code compilation. For example, removing fields or changing field types can create runtime errors for existing clients Compilation-Only Breaking Changes: These affect code generation and compilation without impacting runtime compatibility. An example is adding a new enum value Schema Evolution: Schema changes are typically done within the constraints of the Directed Acyclic Graph (DAG) structure of schema modules. This ensures there are no circular dependencies between modules and maintains consistency during incremental updates Strict Validation: Automated validations, such as CI checks, detect incompatible schema changes during the pull request phase. These validations reference existing operations and client versions to assess impact. TODO how would an architect set up such a CI job? Schema Freeze and Deprecation: Fields being deprecated can be annotated with @deprecated tags and remain in the schema until older client versions are no longer in use. Examples of Practical Schema Updates: Extending Types: Adding new fields to an existing type via extend type. For example: extend type User { friends: [User] } Deprecations: Annotating fields slated for removal with @deprecated and updating client-side queries to avoid referencing these fields Modifications in Input Types: Converting an input type field from non-nullable (String!) to nullable (String) is considered safe ","categories":"","description":"Best practices for managing schema changes in Viaduct.","excerpt":"Best practices for managing schema changes in Viaduct.","ref":"/docs/schema_change_management/","tags":"","title":"Schema Change Management"},{"body":" This is a placeholder page that shows you how to use this template site.\n","categories":"","description":"What does your user need to know to try your project?","excerpt":"What does your user need to know to try your project?","ref":"/docs/service_calls/","tags":"","title":"Service Calls"},{"body":" About Viaduct Viaduct’s mission, vision, and strategy.\nOur vision is that Viaduct will serve as the next-generation application runtime for product engineering teams.\nTo achieve this, we focus on our core mission to empower app developers by delivering a seamless and efficient tenant developer experience. We strive to maximize productivity and spark creativity through simplified APIs, improved performance, and the cultivation of tenant team autonomy.\nDelivering this mission requires us to make many decisions along the way about how to improve our centralized data mesh and runtime. To help guide our decisions and priorities and to instill focus, we have defined four key tenets for how we work:\n","categories":"","description":"","excerpt":" About Viaduct Viaduct’s mission, vision, and strategy.\nOur vision is …","ref":"/about/","tags":"","title":"About Viaduct"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/community/","tags":"","title":"Community"},{"body":"These docs cover how to use Viaduct, including tutorials, how-to guides, and reference materials.\n","categories":"","description":"","excerpt":"These docs cover how to use Viaduct, including tutorials, how-to …","ref":"/docs/","tags":"","title":"Documentation"},{"body":" Viaduct Roadmap Feature Support in the Engine and API.\nFeature Support Name Status Description Resolvers MVP Released /docs/resolvers Subqueries Released /docs/queries/subqueries Observability Released /docs/observability Scopes Releases /docs/scopes Multi-tenancy/ multi module support Released /docs/multiple_modules/ Batch resolvers Preview /docs/resolvers/batch_resolution Mutations Preview /docs/mutations Object Mapping Under Development Object mapping allows the mapping of a generic object type (like a Thrift object type) to a GraphQL type Factory Types Planned for Q4 ‘25 Factory types are a straight-forward way for tenants to share functions in a Kotlin-native manner without breaking our principle of interacting “only through the graph.” More specifically, a factory type defines one or more factory functions that can be used by other modules to construct GRTs. Named Fragments Planned for Q3 ‘25 Reusable part of a GraphQL query that you can define once and use in multiple required selection sets. Visibility Planned for Q4 ‘25 Implement a @visibility directive that controls what internal module code can see. Subscriptions Planned for H! ‘26 Support for GraphQL Subscriptions Parent/Child Relationships Planned for H1 ‘26 In the context of Viaduct, parent-child relationships define hierarchical or associated data relationships across GraphQL types. These relationships allow one type (the parent) to reference or contain another type (the child), enabling structured data querying and retrieval. AI generated mock data Planned for H1 ‘26 When testing Viaduct resolvers, engineers need to manually mock out data for these fragments, which is time-consuming and can eventually lead to mocks getting out of sync with the fragments they implement as resolvers evolve over time. This effort will aid with auto-generating mock data. Connections Planned for H1 ‘26 Support for GraphQL Connections ","categories":"","description":"","excerpt":" Viaduct Roadmap Feature Support in the Engine and API.\nFeature …","ref":"/roadmap/","tags":"","title":"Viaduct Roadmap"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"},{"body":" Viaduct: A GraphQL Server Learn More Download A multitenant alternative to microservices\nViaduct is a GraphQL-based system that provides a unified interface for accessing and interacting with any data source.\nIt can be used by services as a way to access data (efficiently and safely), as well as native and web clients to interact with presentational UI schema.\nViaduct provides you with one global schema and query system. Regardless of the engineering ownership or backing service, data access and mutations should follow a reliable and consistent pattern. The code which hydrates such queries should be maintained by the team which owns the data, to prevent the need to implement such logic by every team querying it.\nThe Viaduct engine is in production, at scale, at Airbnb where it has proven reliable. The developer API of Viaduct is under active development. In our roadmap we indicate which parts of the API are more or less subject to future change. This is a good time to join the project and influence the direction that this API takes!\nBe tenant-developer centric Seek to understand tenant engineers’ experiences, challenges and opportunities as a means to improve the frictions that exist today with the Viaduct framework.\nBe opinionated Approach solutions to problems with an opinionated view as a means to create clarity for tenant developers over excessive choice and unnecessary complexity.\nDeliver incrementally Start small and improve continuously through iteration on our technical solutions and processes. Ship incremental functionality on a frequent cadence as a means to build on an idea vs be stunted by perfection and a “solving for everything” mentality.\nScale for the future Build a system that can grow in reach and capability to more tenant engineers.\nViaduct is a system intended to host large-scale application logic in a serverless manner. By “application logic” we do not mean specialized systems like search backends or credit-risk scoring engines, but rather the kind of generalized business logic that sits in front of transactional databases. If you are building an ad-serving system, you wouldn’t use Viaduct for actually serving the ads, but you could use it to host the entire ads-management system.\nTrusted By\nContributions welcome! We do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more\nFollow us on Mastodon! For announcement of latest features etc.\nRead more\nDiscussions Join the community to ask questions, share ideas, and discuss Viaduct-related topics.\nRead more\n","categories":"","description":"","excerpt":" Viaduct: A GraphQL Server Learn More Download A multitenant …","ref":"/","tags":"","title":"Viaduct"}]